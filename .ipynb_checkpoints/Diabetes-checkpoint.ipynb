{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>first</th>\n",
       "      <th>last</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>income</th>\n",
       "      <th>household_size</th>\n",
       "      <th>...</th>\n",
       "      <th>trigs</th>\n",
       "      <th>wbc</th>\n",
       "      <th>hgb</th>\n",
       "      <th>hct</th>\n",
       "      <th>platelets</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>a1c</th>\n",
       "      <th>hdl</th>\n",
       "      <th>grip_strength</th>\n",
       "      <th>fev1_fvc_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69220</td>\n",
       "      <td>Gwendolyn</td>\n",
       "      <td>Runolfsson</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>36.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63030</td>\n",
       "      <td>Augustus</td>\n",
       "      <td>Farrell</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>5.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64051</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Schmeler</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>256.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>5.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65141</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Bechtelar</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>16.300</td>\n",
       "      <td>5.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64632</td>\n",
       "      <td>Hayden</td>\n",
       "      <td>Brekke</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>306.0</td>\n",
       "      <td>212.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn      first        last  gender  age  race  education  marital  \\\n",
       "0  69220  Gwendolyn  Runolfsson       1   21     7        2.0      6.0   \n",
       "1  63030   Augustus     Farrell       0   21     1        2.0      6.0   \n",
       "2  64051      Aaron    Schmeler       0   21     2        3.0      5.0   \n",
       "3  65141        Bob   Bechtelar       0   21     1        2.0      5.0   \n",
       "4  64632     Hayden      Brekke       0   21     2        3.0      5.0   \n",
       "\n",
       "   income  household_size  ...  trigs  wbc   hgb   hct  platelets  s_cotinine  \\\n",
       "0     1.0               2  ...   54.0  6.0  12.7  36.1      157.0       0.654   \n",
       "1     3.0               4  ...   83.0  6.9  15.1  44.4      226.0       0.221   \n",
       "2     4.0               3  ...  256.0  8.2  14.4  41.3      266.0       0.011   \n",
       "3     4.0               4  ...   57.0  6.6  14.7  43.0      206.0      16.300   \n",
       "4    10.0               2  ...   70.0  7.8  15.6  45.1      306.0     212.000   \n",
       "\n",
       "   a1c   hdl  grip_strength  fev1_fvc_ratio  \n",
       "0  5.0  47.0           50.3            0.78  \n",
       "1  5.2  40.0           90.1            0.84  \n",
       "2  5.1  38.0           72.7            0.83  \n",
       "3  5.1  55.0           86.6            0.83  \n",
       "4  6.0  39.0           94.4            0.83  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "df=pd.read_csv(\"Resources/Adults_Diabetes_NHANES_2011_2012.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seqn</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>income</th>\n",
       "      <th>household_size</th>\n",
       "      <th>insurance</th>\n",
       "      <th>gen_health</th>\n",
       "      <th>...</th>\n",
       "      <th>glob</th>\n",
       "      <th>trigs</th>\n",
       "      <th>wbc</th>\n",
       "      <th>hgb</th>\n",
       "      <th>hct</th>\n",
       "      <th>platelets</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>a1c</th>\n",
       "      <th>hdl</th>\n",
       "      <th>grip_strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69220</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>36.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63030</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.8</td>\n",
       "      <td>83.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>5.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64051</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>14.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>5.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65141</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>16.300</td>\n",
       "      <td>5.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>86.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64632</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>306.0</td>\n",
       "      <td>212.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>94.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seqn  gender  age  race  education  marital  income  household_size  \\\n",
       "0  69220       1   21     7        2.0      6.0     1.0               2   \n",
       "1  63030       0   21     1        2.0      6.0     3.0               4   \n",
       "2  64051       0   21     2        3.0      5.0     4.0               3   \n",
       "3  65141       0   21     1        2.0      5.0     4.0               4   \n",
       "4  64632       0   21     2        3.0      5.0    10.0               2   \n",
       "\n",
       "   insurance  gen_health  ...  glob  trigs  wbc   hgb   hct  platelets  \\\n",
       "0          1         3.0  ...   2.9   54.0  6.0  12.7  36.1      157.0   \n",
       "1          2         3.0  ...   2.8   83.0  6.9  15.1  44.4      226.0   \n",
       "2          1         3.0  ...   3.0  256.0  8.2  14.4  41.3      266.0   \n",
       "3          1         4.0  ...   2.6   57.0  6.6  14.7  43.0      206.0   \n",
       "4          1         2.0  ...   2.9   70.0  7.8  15.6  45.1      306.0   \n",
       "\n",
       "   s_cotinine  a1c   hdl  grip_strength  \n",
       "0       0.654  5.0  47.0           50.3  \n",
       "1       0.221  5.2  40.0           90.1  \n",
       "2       0.011  5.1  38.0           72.7  \n",
       "3      16.300  5.1  55.0           86.6  \n",
       "4     212.000  6.0  39.0           94.4  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1=df.drop(columns=['first', 'last','drinks_day', 'depression','fev1_fvc_ratio'])\n",
    "#Remember to Add back SEQN for ETL\n",
    "\n",
    "df_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5206"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3260"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df_1.dropna()\n",
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmi</th>\n",
       "      <th>bmi_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>32.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2552</th>\n",
       "      <td>30.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>26.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>37.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>33.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>30.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>29.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>27.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>30.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>54.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>31.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>27.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>33.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>28.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>23.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4548</th>\n",
       "      <td>29.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>18.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>34.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>20.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>18.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>24.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>23.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>24.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>34.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>39.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>33.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>25.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>38.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>33.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>21.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>30.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>35.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>33.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>23.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>37.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>24.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4523</th>\n",
       "      <td>31.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>31.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>37.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4633</th>\n",
       "      <td>25.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>32.5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>26.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4718</th>\n",
       "      <td>30.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>28.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bmi  bmi_group\n",
       "1599  32.1          2\n",
       "2552  30.6          2\n",
       "424   26.3          1\n",
       "2356  37.1          2\n",
       "2810  33.6          2\n",
       "1817  24.4          0\n",
       "2596  30.6          2\n",
       "2750  29.3          1\n",
       "1350  27.9          1\n",
       "4720  30.2          2\n",
       "3156  54.5          2\n",
       "2075  31.3          2\n",
       "3879  27.6          1\n",
       "1716  33.3          2\n",
       "2600  28.1          1\n",
       "1719  23.3          0\n",
       "4548  29.9          1\n",
       "1107  18.6          0\n",
       "3610  34.1          2\n",
       "2729  20.5          0\n",
       "360   18.1          0\n",
       "148   24.6          0\n",
       "4359  23.2          0\n",
       "578   24.2          0\n",
       "3313  34.4          2\n",
       "846   39.3          2\n",
       "2065  33.3          2\n",
       "808   25.2          1\n",
       "275   38.5          2\n",
       "1162  33.8          2\n",
       "562   21.7          0\n",
       "802   22.0          0\n",
       "3316  30.3          2\n",
       "2340  35.5          2\n",
       "4081  33.6          2\n",
       "1363  23.9          0\n",
       "1128  24.0          0\n",
       "1701  24.9          0\n",
       "4156  37.1          2\n",
       "140   24.9          0\n",
       "4523  31.6          2\n",
       "2839  31.4          2\n",
       "4223  37.0          2\n",
       "4633  25.3          1\n",
       "453   18.0          0\n",
       "1614  32.5          2\n",
       "16    22.0          0\n",
       "1570  26.2          1\n",
       "4718  30.3          2\n",
       "4546  28.3          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BMI \n",
    "#0= BMI less than 25\n",
    "#1= BMI less than 30 and BMI great than 24\n",
    "#2=BMI great than 30\n",
    "\n",
    "conditions = [\n",
    "   df1['bmi'] <25,\n",
    "    (df1['bmi'] >=25) & (df1['bmi'] <30),\n",
    "   df1['bmi'] >=30\n",
    "]\n",
    "choices = [0,1, 2]\n",
    "df1['bmi_group'] = np.select(conditions, choices, default=1)\n",
    "\n",
    "#df1['bmi_group'] = 1\n",
    "#df1.loc[df1['bmi'] >=30,'bmi_group'] = 2\n",
    "#df1.loc[df1['bmi'] <24,'bmi_group']= 0\n",
    "\n",
    "df1[[\"bmi\",\"bmi_group\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>age_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3068</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4656</th>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4624</th>\n",
       "      <td>74</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3061</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3541</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>62</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3065</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>54</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4420</th>\n",
       "      <td>70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4901</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2307</th>\n",
       "      <td>46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4478</th>\n",
       "      <td>71</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5110</th>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2275</th>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3921</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  age_group\n",
       "3068   54          3\n",
       "4656   74          4\n",
       "1061   32          2\n",
       "882    30          1\n",
       "4624   74          4\n",
       "3061   54          3\n",
       "1827   40          2\n",
       "3541   60          3\n",
       "3531   60          3\n",
       "525    26          1\n",
       "3747   62          3\n",
       "687    28          1\n",
       "3891   63          3\n",
       "5012   80          4\n",
       "4946   80          4\n",
       "54     21          1\n",
       "4850   80          4\n",
       "2794   51          3\n",
       "446    25          1\n",
       "899    30          1\n",
       "2421   47          3\n",
       "1318   35          2\n",
       "3065   54          3\n",
       "1164   33          2\n",
       "1142   33          2\n",
       "4944   80          4\n",
       "768    29          1\n",
       "3069   54          3\n",
       "223    23          1\n",
       "4420   70          4\n",
       "423    25          1\n",
       "4901   80          4\n",
       "1984   42          2\n",
       "2089   43          2\n",
       "3975   64          3\n",
       "2307   46          3\n",
       "630    27          1\n",
       "3455   59          3\n",
       "542    26          1\n",
       "608    27          1\n",
       "1439   36          2\n",
       "355    24          1\n",
       "1997   42          2\n",
       "2054   43          2\n",
       "4478   71          4\n",
       "626    27          1\n",
       "5110   80          4\n",
       "3880   63          3\n",
       "2275   45          2\n",
       "3921   63          3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Age Group \n",
    "\n",
    "# 0=  0-20\n",
    "# 1=  21-30\n",
    "# 2=  31-45\n",
    "# 3=  46-65\n",
    "# 4=  65+\n",
    "conditions1 = [\n",
    "    (df1['age'] >20)&(df1['age'] <31),\n",
    "    (df1['age'] >30)&(df1['age'] <46),\n",
    "    (df1['age'] >45)&(df1['age'] <66),\n",
    "    df1['age'] >65\n",
    "]\n",
    "choices1 = [1, 2, 3,4]\n",
    "df1['age_group'] = np.select(conditions1, choices1, default=0)\n",
    "\n",
    "\n",
    "#df1['age_group'] = 0\n",
    "#df1.loc[(df1['age'] >20)&(df1['age'] <31),'age_group'] = 1\n",
    "#df1.loc[(df1['age'] >30)&(df1['age'] <46),'age_group']= 2\n",
    "#df1.loc[(df1['age'] >45)&(df1['age'] <66),'age_group'] = 3\n",
    "#df1.loc[df1['age'] >65,'age_group'] = 4\n",
    "\n",
    "df1[[\"age\",\"age_group\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sys_bp</th>\n",
       "      <th>dia_bp</th>\n",
       "      <th>bp_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>120.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>116.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>114.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>120.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>116.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>190.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>144.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4329</th>\n",
       "      <td>154.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>134.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>156.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>116.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4511</th>\n",
       "      <td>126.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4632</th>\n",
       "      <td>122.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4587</th>\n",
       "      <td>154.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4161</th>\n",
       "      <td>124.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>128.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>114.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>106.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>124.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>120.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>148.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>166.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>116.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3367</th>\n",
       "      <td>108.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>118.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>126.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1556</th>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>128.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>118.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>102.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4638</th>\n",
       "      <td>114.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>114.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3667</th>\n",
       "      <td>150.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>132.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>100.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>110.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>106.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>120.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3395</th>\n",
       "      <td>110.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>164.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>120.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>116.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>122.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>158.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>112.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>134.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>108.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>144.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2563</th>\n",
       "      <td>114.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sys_bp  dia_bp  bp_group\n",
       "292    120.0    70.0         1\n",
       "62     116.0    80.0         2\n",
       "4386   114.0    50.0         0\n",
       "1147   120.0    84.0         2\n",
       "4378   116.0    52.0         0\n",
       "4912   190.0    70.0         2\n",
       "3035   144.0    66.0         2\n",
       "4329   154.0    78.0         2\n",
       "116    134.0    46.0         2\n",
       "4851   156.0    76.0         2\n",
       "4404   116.0    64.0         0\n",
       "4511   126.0    64.0         1\n",
       "4632   122.0    72.0         1\n",
       "4587   154.0    90.0         2\n",
       "4161   124.0    84.0         2\n",
       "3386   128.0    88.0         2\n",
       "158    114.0    76.0         0\n",
       "119    106.0    66.0         0\n",
       "317    124.0    74.0         1\n",
       "4447   120.0    74.0         1\n",
       "3339   148.0    74.0         2\n",
       "2920   166.0   108.0         2\n",
       "1791   116.0    80.0         2\n",
       "3367   108.0    58.0         0\n",
       "547    118.0    66.0         0\n",
       "4623   126.0    64.0         1\n",
       "1061   112.0    74.0         0\n",
       "1556   102.0    62.0         0\n",
       "3899   128.0    76.0         1\n",
       "1793   118.0    70.0         0\n",
       "535    102.0    56.0         0\n",
       "4638   114.0    62.0         0\n",
       "809    114.0    68.0         0\n",
       "3667   150.0    82.0         2\n",
       "4057   132.0    76.0         2\n",
       "4465   100.0    58.0         0\n",
       "471    110.0    54.0         0\n",
       "3410   106.0    64.0         0\n",
       "347    120.0    58.0         1\n",
       "3395   110.0    72.0         0\n",
       "1629   164.0    84.0         2\n",
       "751    120.0    74.0         1\n",
       "817    116.0    74.0         0\n",
       "4993   122.0    72.0         1\n",
       "1389   158.0   100.0         2\n",
       "3132   112.0    62.0         0\n",
       "4439   134.0    68.0         2\n",
       "792    108.0    52.0         0\n",
       "3524   144.0    86.0         2\n",
       "2563   114.0    86.0         2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Blood Pressure Group \n",
    "#Systolic Blood Pressure less than 120 and Diastolic Blood Pressure of less than 80\n",
    "#Systolic Blood Pressure between 120 and 129 and Diastolic Blood Pressure of less than 80\n",
    "#Systolic Blood Pressure greater than 130 or  Diastolic Blood Pressure of greater than 80\n",
    "\n",
    "conditions2 = [\n",
    "    (df1['sys_bp'] <120)&(df1['dia_bp'] <80),\n",
    "   (df1['sys_bp'] >119)&(df1['sys_bp'] <=129)&(df1['dia_bp'] <80),\n",
    "    (df1['sys_bp'] >129)|(df1['dia_bp'] >=80),\n",
    " \n",
    "]\n",
    "choices2 = [0, 1, 2]\n",
    "df1['bp_group'] = np.select(conditions2, choices2, default=0)\n",
    "#df1['bp_group'] = 0\n",
    "#df1.loc[(df['sys_bp'] <120)&(df1['dia_bp'] <80),'bp_group'] = 0\n",
    "#df1.loc[(df['sys_bp'] >119)&(df1['sys_bp'] <=129)&(df['dia_bp'] <80),'bp_group'] = 1\n",
    "#df1.loc[(df['sys_bp'] >129)|(df1['dia_bp'] >=80),'bp_group'] = 2\n",
    "\n",
    "\n",
    "df1[[\"sys_bp\",\"dia_bp\",\"bp_group\"]].sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop(columns=['seqn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"diabetes\"]= df2[\"diabetes\"]-1\n",
    "\n",
    "target = df2[\"diabetes\"]\n",
    "target_names = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>education</th>\n",
       "      <th>marital</th>\n",
       "      <th>income</th>\n",
       "      <th>household_size</th>\n",
       "      <th>insurance</th>\n",
       "      <th>gen_health</th>\n",
       "      <th>asthma</th>\n",
       "      <th>...</th>\n",
       "      <th>hgb</th>\n",
       "      <th>hct</th>\n",
       "      <th>platelets</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>a1c</th>\n",
       "      <th>hdl</th>\n",
       "      <th>grip_strength</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.7</td>\n",
       "      <td>36.1</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.1</td>\n",
       "      <td>44.4</td>\n",
       "      <td>226.0</td>\n",
       "      <td>0.221</td>\n",
       "      <td>5.2</td>\n",
       "      <td>40.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.4</td>\n",
       "      <td>41.3</td>\n",
       "      <td>266.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>5.1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.7</td>\n",
       "      <td>43.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>16.300</td>\n",
       "      <td>5.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>45.1</td>\n",
       "      <td>306.0</td>\n",
       "      <td>212.000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age  race  education  marital  income  household_size  insurance  \\\n",
       "0       1   21     7        2.0      6.0     1.0               2          1   \n",
       "1       0   21     1        2.0      6.0     3.0               4          2   \n",
       "2       0   21     2        3.0      5.0     4.0               3          1   \n",
       "3       0   21     1        2.0      5.0     4.0               4          1   \n",
       "4       0   21     2        3.0      5.0    10.0               2          1   \n",
       "\n",
       "   gen_health  asthma  ...   hgb   hct  platelets  s_cotinine  a1c   hdl  \\\n",
       "0         3.0     2.0  ...  12.7  36.1      157.0       0.654  5.0  47.0   \n",
       "1         3.0     1.0  ...  15.1  44.4      226.0       0.221  5.2  40.0   \n",
       "2         3.0     2.0  ...  14.4  41.3      266.0       0.011  5.1  38.0   \n",
       "3         4.0     2.0  ...  14.7  43.0      206.0      16.300  5.1  55.0   \n",
       "4         2.0     2.0  ...  15.6  45.1      306.0     212.000  6.0  39.0   \n",
       "\n",
       "   grip_strength  bmi_group  age_group  bp_group  \n",
       "0           50.3          0          1         0  \n",
       "1           90.1          1          1         0  \n",
       "2           72.7          1          1         0  \n",
       "3           86.6          0          1         0  \n",
       "4           94.4          2          1         2  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df2.drop(\"diabetes\", axis=1) \n",
    "feature_names = data.columns \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8503067484662576"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier() \n",
    "clf = clf.fit(X_train, y_train) \n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9226993865030675"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf = RandomForestClassifier(n_estimators=75) \n",
    "rf = rf.fit(X_train, y_train) \n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_imp=sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "feature_imp[1][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1c',\n",
       " 'glucose',\n",
       " 'alb_cr_ratio',\n",
       " 't_chol',\n",
       " 'trigs',\n",
       " 'platelets',\n",
       " 'grip_strength',\n",
       " 'ldh',\n",
       " 'cr',\n",
       " 'alk_phos',\n",
       " 'wbc',\n",
       " 'potassium',\n",
       " 'alt',\n",
       " 'hct',\n",
       " 'bun',\n",
       " 'ca',\n",
       " 'u_acid',\n",
       " 'cpk',\n",
       " 'sodium',\n",
       " 'hdl',\n",
       " 'hgb',\n",
       " 'glob',\n",
       " 'ast',\n",
       " 't_protein',\n",
       " 'iron',\n",
       " 'hypertension',\n",
       " 'gen_health',\n",
       " 'phos',\n",
       " 's_cotinine',\n",
       " 'chloride',\n",
       " 't_bilirubin']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remlist=['age', 'bmi','height_cm','waist_cm','weight_kg','dia_bp','sys_bp']\n",
    "feats= []\n",
    "\n",
    "for x in feature_imp: \n",
    "    if x[0]>0.01 and x[1] not in remlist:\n",
    "        feats.append(x[1])\n",
    "        \n",
    "\n",
    "\n",
    "feats        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a1c',\n",
       " 'glucose',\n",
       " 'alb_cr_ratio',\n",
       " 't_chol',\n",
       " 'trigs',\n",
       " 'platelets',\n",
       " 'grip_strength',\n",
       " 'ldh',\n",
       " 'cr',\n",
       " 'alk_phos',\n",
       " 'wbc',\n",
       " 'potassium',\n",
       " 'alt',\n",
       " 'hct',\n",
       " 'bun',\n",
       " 'ca',\n",
       " 'u_acid',\n",
       " 'cpk',\n",
       " 'sodium',\n",
       " 'hdl',\n",
       " 'hgb',\n",
       " 'glob',\n",
       " 'ast',\n",
       " 't_protein',\n",
       " 'iron',\n",
       " 'hypertension',\n",
       " 'gen_health',\n",
       " 'phos',\n",
       " 's_cotinine',\n",
       " 'chloride',\n",
       " 't_bilirubin',\n",
       " 'bmi_group',\n",
       " 'age_group',\n",
       " 'bp_group',\n",
       " 'diabetes']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_list=[\"bmi_group\", \"age_group\", \"bp_group\",\"diabetes\"]\n",
    "\n",
    "for x in group_list: \n",
    "    if x not in feats: \n",
    "        feats.append(x)\n",
    "        \n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_df =df2[feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1c</th>\n",
       "      <th>glucose</th>\n",
       "      <th>alb_cr_ratio</th>\n",
       "      <th>t_chol</th>\n",
       "      <th>trigs</th>\n",
       "      <th>platelets</th>\n",
       "      <th>grip_strength</th>\n",
       "      <th>ldh</th>\n",
       "      <th>cr</th>\n",
       "      <th>alk_phos</th>\n",
       "      <th>...</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>gen_health</th>\n",
       "      <th>phos</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>chloride</th>\n",
       "      <th>t_bilirubin</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_group</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.77</td>\n",
       "      <td>118.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.654</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>172.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.221</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>168.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.011</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16.300</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>212.000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>5.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>49.63</td>\n",
       "      <td>185.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>47.2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.011</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>166.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>7.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>187.41</td>\n",
       "      <td>176.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.011</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>6.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>11.43</td>\n",
       "      <td>171.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.269</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>6.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.035</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3260 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a1c  glucose  alb_cr_ratio  t_chol  trigs  platelets  grip_strength  \\\n",
       "0     5.0     82.0         11.77   118.0   54.0      157.0           50.3   \n",
       "1     5.2     81.0          2.37   172.0   83.0      226.0           90.1   \n",
       "2     5.1     87.0          3.73   168.0  256.0      266.0           72.7   \n",
       "3     5.1     91.0          3.74   144.0   57.0      206.0           86.6   \n",
       "4     6.0     89.0          3.13   104.0   70.0      306.0           94.4   \n",
       "...   ...      ...           ...     ...    ...        ...            ...   \n",
       "5196  5.8     98.0         49.63   185.0   80.0      178.0           47.2   \n",
       "5197  6.0    100.0          9.40   166.0  105.0      189.0           75.6   \n",
       "5199  7.0    175.0        187.41   176.0  104.0      273.0           33.1   \n",
       "5201  6.5    126.0         11.43   171.0  130.0      205.0           65.2   \n",
       "5204  6.2    103.0          3.92   181.0   67.0      213.0           45.2   \n",
       "\n",
       "        ldh    cr  alk_phos  ...  hypertension  gen_health  phos  s_cotinine  \\\n",
       "0      75.0  0.44      44.0  ...           2.0         3.0   4.2       0.654   \n",
       "1     137.0  0.81     112.0  ...           2.0         3.0   3.8       0.221   \n",
       "2     112.0  0.82     103.0  ...           2.0         3.0   4.4       0.011   \n",
       "3      87.0  0.73      65.0  ...           2.0         4.0   4.2      16.300   \n",
       "4     104.0  1.07      55.0  ...           2.0         2.0   4.3     212.000   \n",
       "...     ...   ...       ...  ...           ...         ...   ...         ...   \n",
       "5196  127.0  0.55      42.0  ...           1.0         3.0   3.7       0.011   \n",
       "5197  163.0  1.15      49.0  ...           2.0         3.0   3.0       0.011   \n",
       "5199  155.0  0.92      84.0  ...           1.0         3.0   3.9       0.011   \n",
       "5201  119.0  0.73      50.0  ...           2.0         2.0   3.1       0.269   \n",
       "5204  138.0  0.95      80.0  ...           1.0         3.0   3.5       0.035   \n",
       "\n",
       "      chloride  t_bilirubin  bmi_group  age_group  bp_group  diabetes  \n",
       "0        105.0          0.8          0          1         0       1.0  \n",
       "1        102.0          1.2          1          1         0       1.0  \n",
       "2        104.0          0.4          1          1         0       1.0  \n",
       "3        102.0          0.9          0          1         0       1.0  \n",
       "4        104.0          0.8          2          1         2       1.0  \n",
       "...        ...          ...        ...        ...       ...       ...  \n",
       "5196     103.0          0.9          0          4         2       1.0  \n",
       "5197     105.0          1.0          1          4         2       1.0  \n",
       "5199     102.0          0.5          2          4         2       0.0  \n",
       "5201     107.0          0.7          2          4         2       0.0  \n",
       "5204     103.0          1.0          2          4         1       0.0  \n",
       "\n",
       "[3260 rows x 35 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1c</th>\n",
       "      <th>glucose</th>\n",
       "      <th>alb_cr_ratio</th>\n",
       "      <th>t_chol</th>\n",
       "      <th>trigs</th>\n",
       "      <th>platelets</th>\n",
       "      <th>grip_strength</th>\n",
       "      <th>ldh</th>\n",
       "      <th>cr</th>\n",
       "      <th>alk_phos</th>\n",
       "      <th>...</th>\n",
       "      <th>iron</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>gen_health</th>\n",
       "      <th>phos</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>chloride</th>\n",
       "      <th>t_bilirubin</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.77</td>\n",
       "      <td>118.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.654</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>172.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>119.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.221</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>168.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.011</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16.300</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>121.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>212.000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a1c  glucose  alb_cr_ratio  t_chol  trigs  platelets  grip_strength    ldh  \\\n",
       "0  5.0     82.0         11.77   118.0   54.0      157.0           50.3   75.0   \n",
       "1  5.2     81.0          2.37   172.0   83.0      226.0           90.1  137.0   \n",
       "2  5.1     87.0          3.73   168.0  256.0      266.0           72.7  112.0   \n",
       "3  5.1     91.0          3.74   144.0   57.0      206.0           86.6   87.0   \n",
       "4  6.0     89.0          3.13   104.0   70.0      306.0           94.4  104.0   \n",
       "\n",
       "     cr  alk_phos  ...   iron  hypertension  gen_health  phos  s_cotinine  \\\n",
       "0  0.44      44.0  ...  165.0           2.0         3.0   4.2       0.654   \n",
       "1  0.81     112.0  ...  119.0           2.0         3.0   3.8       0.221   \n",
       "2  0.82     103.0  ...   68.0           2.0         3.0   4.4       0.011   \n",
       "3  0.73      65.0  ...   63.0           2.0         4.0   4.2      16.300   \n",
       "4  1.07      55.0  ...  121.0           2.0         2.0   4.3     212.000   \n",
       "\n",
       "   chloride  t_bilirubin  bmi_group  age_group  bp_group  \n",
       "0     105.0          0.8          0          1         0  \n",
       "1     102.0          1.2          1          1         0  \n",
       "2     104.0          0.4          1          1         0  \n",
       "3     102.0          0.9          0          1         0  \n",
       "4     104.0          0.8          2          1         2  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = diab_df.drop(\"diabetes\", axis=1) \n",
    "feature_names = data.columns \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = diab_df[\"diabetes\"].values.reshape(-1, 1)\n",
    "target_names = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of variables is: 34\n"
     ]
    }
   ],
   "source": [
    "numb_variables =len(feature_names.tolist())\n",
    "print(f\"The total number of variables is: {numb_variables}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "###MY CODE STARTS HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULLTIPLE LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train_scaled)\n",
    "plt.scatter(model.predict(X_train_scaled), model.predict(X_train_scaled) - y_train_scaled, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test_scaled), model.predict(X_test_scaled) - y_test_scaled, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y_test_scaled.min(), xmax=y_test_scaled.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6689199878963539, R2: 0.28500183491349296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "MSE = mean_squared_error(y_test_scaled, predictions)\n",
    "r2 = model.score(X_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"MSE: {MSE}, R2: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601226993865031"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier() #model\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9251533742331288"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2171244923073894, 'a1c'),\n",
       " (0.14159017464662857, 'glucose'),\n",
       " (0.04033563916099368, 'alb_cr_ratio'),\n",
       " (0.027941550329338944, 't_chol'),\n",
       " (0.026653750273326317, 'platelets'),\n",
       " (0.02624347887169418, 'trigs'),\n",
       " (0.025297052120388457, 'ldh'),\n",
       " (0.02506681162018428, 'cr'),\n",
       " (0.02384038065560702, 'potassium'),\n",
       " (0.023437831286603792, 'grip_strength'),\n",
       " (0.023077049011410763, 'u_acid'),\n",
       " (0.023000820344757207, 'alk_phos'),\n",
       " (0.022390625834976207, 'cpk'),\n",
       " (0.021553008392466353, 'hdl'),\n",
       " (0.021350570647872612, 'bun'),\n",
       " (0.02045068040367984, 'wbc'),\n",
       " (0.019422131241907767, 'alt'),\n",
       " (0.019293107139802312, 'hct'),\n",
       " (0.01919948459506571, 'ast'),\n",
       " (0.018989805747332028, 'ca'),\n",
       " (0.018607723760869027, 'chloride'),\n",
       " (0.018179912827706878, 'gen_health'),\n",
       " (0.01795007565832322, 't_protein'),\n",
       " (0.017857817995464993, 'glob'),\n",
       " (0.01763448577599942, 'iron'),\n",
       " (0.017425142103149462, 'hgb'),\n",
       " (0.01688265752120986, 'phos'),\n",
       " (0.016817490750511317, 's_cotinine'),\n",
       " (0.016776521921147675, 'sodium'),\n",
       " (0.015590925192449699, 't_bilirubin'),\n",
       " (0.014078912133611388, 'age_group'),\n",
       " (0.012364488970611832, 'hypertension'),\n",
       " (0.008843678593653955, 'bmi_group'),\n",
       " (0.004731722163865794, 'bp_group')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 3, Train/Test Score: 0.915/0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 5, Train/Test Score: 0.901/0.896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 7, Train/Test Score: 0.896/0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 9, Train/Test Score: 0.894/0.894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 11, Train/Test Score: 0.892/0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 13, Train/Test Score: 0.892/0.892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 15, Train/Test Score: 0.889/0.893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 17, Train/Test Score: 0.889/0.891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 19, Train/Test Score: 0.887/0.890\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "# Note: We only use odd numbers because we don't want any ties\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=11 Test Acc: 0.893\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=11 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.910, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.928, total=   0.7s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s remaining:    0.0s\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.898, total=   1.1s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.910, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.910, total=   0.7s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0005, score=0.910, total=   0.2s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0005, score=0.928, total=   1.0s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0005, score=0.898, total=   0.6s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0005, score=0.910, total=   0.3s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0005, score=0.910, total=   0.8s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.910, total=   0.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.928, total=   0.6s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.898, total=   0.7s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.910, total=   0.9s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.910, total=   0.7s\n",
      "[CV] C=1, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-37-5287c59abe55>\", line 3, in <module>\n",
      "    grid.fit(X_train_scaled, y_train)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 736, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 1188, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\", line 715, in evaluate_candidates\n",
      "    cv.split(X, y, groups)))\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\", line 1032, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/svm/_base.py\", line 217, in fit\n",
      "    fit(X, y, sample_weight, solver_type, kernel, random_seed=seed)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/svm/_base.py\", line 276, in _dense_fit\n",
      "    max_iter=self.max_iter, random_seed=random_seed)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/posixpath.py\", line 75, in join\n",
      "    def join(a, *p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-5287c59abe55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This will take the SVC model and try each combination of parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 715\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # List the best parameters for this dataset\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best score\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-42de4c453e2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make predictions with the hypertuned model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \"\"\"\n\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_estimator_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"one\", \"two\",\"three\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_data = [[new data inserted here]]\n",
    "#predicted_class = knn.predict(new_data)\n",
    "#print(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEPLEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=102, activation='relu', input_dim=34))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['Precision','Recall'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2445, 3)\n",
      "_----------\n",
      "(2445, 34)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_categorical.shape)\n",
    "print(\"_----------\")\n",
    "print(X_train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "77/77 - 0s - loss: 0.4529 - precision: 0.8789 - recall: 0.8016\n",
      "Epoch 2/250\n",
      "77/77 - 0s - loss: 0.2956 - precision: 0.9148 - recall: 0.9006\n",
      "Epoch 3/250\n",
      "77/77 - 1s - loss: 0.2638 - precision: 0.9284 - recall: 0.9117\n",
      "Epoch 4/250\n",
      "77/77 - 0s - loss: 0.2324 - precision: 0.9341 - recall: 0.9215\n",
      "Epoch 5/250\n",
      "77/77 - 0s - loss: 0.2143 - precision: 0.9393 - recall: 0.9247\n",
      "Epoch 6/250\n",
      "77/77 - 0s - loss: 0.1729 - precision: 0.9501 - recall: 0.9354\n",
      "Epoch 7/250\n",
      "77/77 - 1s - loss: 0.1747 - precision: 0.9537 - recall: 0.9354\n",
      "Epoch 8/250\n",
      "77/77 - 0s - loss: 0.1226 - precision: 0.9638 - recall: 0.9460\n",
      "Epoch 9/250\n",
      "77/77 - 0s - loss: 0.0950 - precision: 0.9693 - recall: 0.9562\n",
      "Epoch 10/250\n",
      "77/77 - 0s - loss: 0.0707 - precision: 0.9786 - recall: 0.9714\n",
      "Epoch 11/250\n",
      "77/77 - 0s - loss: 0.0966 - precision: 0.9741 - recall: 0.9693\n",
      "Epoch 12/250\n",
      "77/77 - 0s - loss: 0.0476 - precision: 0.9873 - recall: 0.9832\n",
      "Epoch 13/250\n",
      "77/77 - 0s - loss: 0.0494 - precision: 0.9857 - recall: 0.9849\n",
      "Epoch 14/250\n",
      "77/77 - 0s - loss: 0.0335 - precision: 0.9902 - recall: 0.9885\n",
      "Epoch 15/250\n",
      "77/77 - 0s - loss: 0.0112 - precision: 0.9963 - recall: 0.9951\n",
      "Epoch 16/250\n",
      "77/77 - 0s - loss: 0.0020 - precision: 1.0000 - recall: 0.9996\n",
      "Epoch 17/250\n",
      "77/77 - 0s - loss: 0.0019 - precision: 0.9996 - recall: 0.9996\n",
      "Epoch 18/250\n",
      "77/77 - 0s - loss: 0.0051 - precision: 0.9992 - recall: 0.9992\n",
      "Epoch 19/250\n",
      "77/77 - 0s - loss: 0.0034 - precision: 0.9988 - recall: 0.9988\n",
      "Epoch 20/250\n",
      "77/77 - 0s - loss: 6.5620e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 21/250\n",
      "77/77 - 1s - loss: 2.1475e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 22/250\n",
      "77/77 - 1s - loss: 1.3706e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 23/250\n",
      "77/77 - 0s - loss: 1.0324e-04 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 24/250\n",
      "77/77 - 0s - loss: 8.1936e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 25/250\n",
      "77/77 - 1s - loss: 6.6692e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 26/250\n",
      "77/77 - 0s - loss: 5.5589e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 27/250\n",
      "77/77 - 0s - loss: 4.6852e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 28/250\n",
      "77/77 - 0s - loss: 4.0054e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 29/250\n",
      "77/77 - 0s - loss: 3.4764e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 30/250\n",
      "77/77 - 0s - loss: 3.0339e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 31/250\n",
      "77/77 - 0s - loss: 2.6750e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 32/250\n",
      "77/77 - 0s - loss: 2.3733e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 33/250\n",
      "77/77 - 0s - loss: 2.1192e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 34/250\n",
      "77/77 - 0s - loss: 1.8967e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 35/250\n",
      "77/77 - 0s - loss: 1.7099e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 36/250\n",
      "77/77 - 0s - loss: 1.5465e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 37/250\n",
      "77/77 - 0s - loss: 1.4051e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 38/250\n",
      "77/77 - 0s - loss: 1.2799e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 39/250\n",
      "77/77 - 0s - loss: 1.1680e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 40/250\n",
      "77/77 - 0s - loss: 1.0698e-05 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 41/250\n",
      "77/77 - 0s - loss: 9.8257e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 42/250\n",
      "77/77 - 0s - loss: 9.0435e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 43/250\n",
      "77/77 - 0s - loss: 8.3392e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 44/250\n",
      "77/77 - 0s - loss: 7.7098e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 45/250\n",
      "77/77 - 0s - loss: 7.1149e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 46/250\n",
      "77/77 - 0s - loss: 6.5458e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 47/250\n",
      "77/77 - 0s - loss: 6.0839e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 48/250\n",
      "77/77 - 0s - loss: 5.6609e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 49/250\n",
      "77/77 - 0s - loss: 5.2770e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 50/250\n",
      "77/77 - 0s - loss: 4.9291e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 51/250\n",
      "77/77 - 0s - loss: 4.6036e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 52/250\n",
      "77/77 - 0s - loss: 4.2975e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 53/250\n",
      "77/77 - 1s - loss: 4.0199e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 54/250\n",
      "77/77 - 1s - loss: 3.7688e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 55/250\n",
      "77/77 - 0s - loss: 3.5346e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 56/250\n",
      "77/77 - 0s - loss: 3.3161e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 57/250\n",
      "77/77 - 0s - loss: 3.1238e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 58/250\n",
      "77/77 - 0s - loss: 2.9299e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 59/250\n",
      "77/77 - 0s - loss: 2.7550e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 60/250\n",
      "77/77 - 0s - loss: 2.5938e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 61/250\n",
      "77/77 - 0s - loss: 2.4462e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 62/250\n",
      "77/77 - 0s - loss: 2.3068e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 63/250\n",
      "77/77 - 0s - loss: 2.1765e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 64/250\n",
      "77/77 - 0s - loss: 2.0569e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 65/250\n",
      "77/77 - 0s - loss: 1.9403e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 66/250\n",
      "77/77 - 0s - loss: 1.8344e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 67/250\n",
      "77/77 - 0s - loss: 1.7350e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 68/250\n",
      "77/77 - 0s - loss: 1.6403e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 69/250\n",
      "77/77 - 0s - loss: 1.5501e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 70/250\n",
      "77/77 - 0s - loss: 1.4654e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 71/250\n",
      "77/77 - 0s - loss: 1.3876e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 72/250\n",
      "77/77 - 0s - loss: 1.3147e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 73/250\n",
      "77/77 - 0s - loss: 1.2467e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 74/250\n",
      "77/77 - 0s - loss: 1.1809e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 75/250\n",
      "77/77 - 0s - loss: 1.1174e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 76/250\n",
      "77/77 - 0s - loss: 1.0598e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 77/250\n",
      "77/77 - 0s - loss: 1.0046e-06 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 78/250\n",
      "77/77 - 0s - loss: 9.5423e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 79/250\n",
      "77/77 - 0s - loss: 9.0592e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 80/250\n",
      "77/77 - 0s - loss: 8.5882e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 81/250\n",
      "77/77 - 0s - loss: 8.1533e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 82/250\n",
      "77/77 - 0s - loss: 7.7374e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 83/250\n",
      "77/77 - 0s - loss: 7.3484e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 84/250\n",
      "77/77 - 0s - loss: 6.9852e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 85/250\n",
      "77/77 - 0s - loss: 6.6395e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 86/250\n",
      "77/77 - 0s - loss: 6.3021e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 87/250\n",
      "77/77 - 0s - loss: 6.0076e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 88/250\n",
      "77/77 - 0s - loss: 5.7020e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 89/250\n",
      "77/77 - 0s - loss: 5.4221e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 90/250\n",
      "77/77 - 0s - loss: 5.1544e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 91/250\n",
      "77/77 - 0s - loss: 4.8892e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 92/250\n",
      "77/77 - 0s - loss: 4.6489e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 93/250\n",
      "77/77 - 0s - loss: 4.4231e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 94/250\n",
      "77/77 - 1s - loss: 4.2140e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 95/250\n",
      "77/77 - 0s - loss: 4.0063e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 96/250\n",
      "77/77 - 0s - loss: 3.8181e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 97/250\n",
      "77/77 - 0s - loss: 3.6269e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 98/250\n",
      "77/77 - 0s - loss: 3.4534e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 99/250\n",
      "77/77 - 0s - loss: 3.2852e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 100/250\n",
      "77/77 - 0s - loss: 3.1287e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 101/250\n",
      "77/77 - 0s - loss: 2.9775e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 102/250\n",
      "77/77 - 0s - loss: 2.8347e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 103/250\n",
      "77/77 - 0s - loss: 2.6977e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 104/250\n",
      "77/77 - 0s - loss: 2.5655e-07 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/250\n",
      "77/77 - 0s - loss: 2.4451e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 106/250\n",
      "77/77 - 0s - loss: 2.3330e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 107/250\n",
      "77/77 - 0s - loss: 2.2213e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 108/250\n",
      "77/77 - 0s - loss: 2.1145e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 109/250\n",
      "77/77 - 0s - loss: 2.0107e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 110/250\n",
      "77/77 - 0s - loss: 1.9166e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 111/250\n",
      "77/77 - 0s - loss: 1.8298e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 112/250\n",
      "77/77 - 0s - loss: 1.7460e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 113/250\n",
      "77/77 - 0s - loss: 1.6606e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 114/250\n",
      "77/77 - 0s - loss: 1.5860e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 115/250\n",
      "77/77 - 0s - loss: 1.5144e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 116/250\n",
      "77/77 - 0s - loss: 1.4271e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 117/250\n",
      "77/77 - 0s - loss: 1.3608e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 118/250\n",
      "77/77 - 0s - loss: 1.3028e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 119/250\n",
      "77/77 - 0s - loss: 1.2423e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 120/250\n",
      "77/77 - 0s - loss: 1.1823e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 121/250\n",
      "77/77 - 0s - loss: 1.1253e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 122/250\n",
      "77/77 - 0s - loss: 1.0775e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 123/250\n",
      "77/77 - 0s - loss: 1.0288e-07 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 124/250\n",
      "77/77 - 0s - loss: 9.7902e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 125/250\n",
      "77/77 - 0s - loss: 9.3514e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 126/250\n",
      "77/77 - 0s - loss: 8.9370e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 127/250\n",
      "77/77 - 0s - loss: 8.5323e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 128/250\n",
      "77/77 - 0s - loss: 8.1667e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 129/250\n",
      "77/77 - 0s - loss: 7.7912e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 130/250\n",
      "77/77 - 0s - loss: 7.4548e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 131/250\n",
      "77/77 - 0s - loss: 7.1087e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 132/250\n",
      "77/77 - 0s - loss: 6.8015e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 133/250\n",
      "77/77 - 0s - loss: 6.4895e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 134/250\n",
      "77/77 - 0s - loss: 6.2213e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 135/250\n",
      "77/77 - 0s - loss: 5.9434e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 136/250\n",
      "77/77 - 0s - loss: 5.6362e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 137/250\n",
      "77/77 - 0s - loss: 5.3681e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 138/250\n",
      "77/77 - 1s - loss: 5.1340e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 139/250\n",
      "77/77 - 1s - loss: 4.9195e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 140/250\n",
      "77/77 - 0s - loss: 4.6611e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 141/250\n",
      "77/77 - 0s - loss: 4.4271e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 142/250\n",
      "77/77 - 0s - loss: 4.2564e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 143/250\n",
      "77/77 - 0s - loss: 4.0809e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 144/250\n",
      "77/77 - 0s - loss: 3.9249e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 145/250\n",
      "77/77 - 0s - loss: 3.7591e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 146/250\n",
      "77/77 - 0s - loss: 3.5933e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 147/250\n",
      "77/77 - 0s - loss: 3.4617e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 148/250\n",
      "77/77 - 0s - loss: 3.2911e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 149/250\n",
      "77/77 - 0s - loss: 3.1399e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 150/250\n",
      "77/77 - 0s - loss: 2.9936e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 151/250\n",
      "77/77 - 0s - loss: 2.9010e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 152/250\n",
      "77/77 - 0s - loss: 2.7596e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 153/250\n",
      "77/77 - 1s - loss: 2.6572e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 154/250\n",
      "77/77 - 0s - loss: 2.5256e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 155/250\n",
      "77/77 - 1s - loss: 2.4329e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 156/250\n",
      "77/77 - 1s - loss: 2.3549e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 157/250\n",
      "77/77 - 0s - loss: 2.2623e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 158/250\n",
      "77/77 - 0s - loss: 2.1111e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 159/250\n",
      "77/77 - 1s - loss: 2.0185e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 160/250\n",
      "77/77 - 1s - loss: 1.9454e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 161/250\n",
      "77/77 - 1s - loss: 1.8576e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 162/250\n",
      "77/77 - 0s - loss: 1.7504e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 163/250\n",
      "77/77 - 0s - loss: 1.6723e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 164/250\n",
      "77/77 - 1s - loss: 1.6041e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 165/250\n",
      "77/77 - 0s - loss: 1.5163e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 166/250\n",
      "77/77 - 0s - loss: 1.4481e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 167/250\n",
      "77/77 - 1s - loss: 1.3847e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 168/250\n",
      "77/77 - 0s - loss: 1.3457e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 169/250\n",
      "77/77 - 1s - loss: 1.2774e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 170/250\n",
      "77/77 - 0s - loss: 1.2238e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 171/250\n",
      "77/77 - 1s - loss: 1.1945e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 172/250\n",
      "77/77 - 1s - loss: 1.1458e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 173/250\n",
      "77/77 - 1s - loss: 1.1068e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 174/250\n",
      "77/77 - 1s - loss: 1.0336e-08 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 175/250\n",
      "77/77 - 1s - loss: 9.9951e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 176/250\n",
      "77/77 - 0s - loss: 9.3612e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 177/250\n",
      "77/77 - 0s - loss: 8.9712e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 178/250\n",
      "77/77 - 0s - loss: 8.5324e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 179/250\n",
      "77/77 - 0s - loss: 8.2886e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 180/250\n",
      "77/77 - 0s - loss: 7.9473e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 181/250\n",
      "77/77 - 0s - loss: 7.6060e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 182/250\n",
      "77/77 - 1s - loss: 7.4597e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 183/250\n",
      "77/77 - 1s - loss: 6.8746e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 184/250\n",
      "77/77 - 1s - loss: 6.5334e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 185/250\n",
      "77/77 - 1s - loss: 6.3383e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 186/250\n",
      "77/77 - 1s - loss: 5.9970e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 187/250\n",
      "77/77 - 0s - loss: 5.9483e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 188/250\n",
      "77/77 - 0s - loss: 5.7532e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 189/250\n",
      "77/77 - 0s - loss: 5.5095e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 190/250\n",
      "77/77 - 0s - loss: 5.2657e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 191/250\n",
      "77/77 - 0s - loss: 4.7781e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 192/250\n",
      "77/77 - 1s - loss: 4.4856e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 193/250\n",
      "77/77 - 0s - loss: 4.4368e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 194/250\n",
      "77/77 - 1s - loss: 4.3881e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 195/250\n",
      "77/77 - 1s - loss: 4.1443e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 196/250\n",
      "77/77 - 0s - loss: 3.9980e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 197/250\n",
      "77/77 - 0s - loss: 3.9005e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 198/250\n",
      "77/77 - 1s - loss: 3.7055e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 199/250\n",
      "77/77 - 0s - loss: 3.4617e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 200/250\n",
      "77/77 - 0s - loss: 3.3154e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 201/250\n",
      "77/77 - 0s - loss: 3.2179e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 202/250\n",
      "77/77 - 0s - loss: 2.9254e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 203/250\n",
      "77/77 - 0s - loss: 2.8766e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 204/250\n",
      "77/77 - 1s - loss: 2.6328e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 205/250\n",
      "77/77 - 1s - loss: 2.4866e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 206/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 - 1s - loss: 2.2428e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 207/250\n",
      "77/77 - 1s - loss: 2.1453e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 208/250\n",
      "77/77 - 1s - loss: 1.9990e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 209/250\n",
      "77/77 - 1s - loss: 1.9015e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 210/250\n",
      "77/77 - 0s - loss: 1.8040e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 211/250\n",
      "77/77 - 0s - loss: 1.7552e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 212/250\n",
      "77/77 - 0s - loss: 1.6577e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 213/250\n",
      "77/77 - 0s - loss: 1.6577e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 214/250\n",
      "77/77 - 0s - loss: 1.6090e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 215/250\n",
      "77/77 - 0s - loss: 1.4627e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 216/250\n",
      "77/77 - 0s - loss: 1.4627e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 217/250\n",
      "77/77 - 0s - loss: 1.3164e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 218/250\n",
      "77/77 - 0s - loss: 1.2677e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 219/250\n",
      "77/77 - 0s - loss: 1.1702e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 220/250\n",
      "77/77 - 0s - loss: 1.1214e-09 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 221/250\n",
      "77/77 - 0s - loss: 9.7513e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 222/250\n",
      "77/77 - 0s - loss: 9.2637e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 223/250\n",
      "77/77 - 0s - loss: 9.2637e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 224/250\n",
      "77/77 - 0s - loss: 8.2886e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 225/250\n",
      "77/77 - 0s - loss: 7.8010e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 226/250\n",
      "77/77 - 0s - loss: 7.8010e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 227/250\n",
      "77/77 - 0s - loss: 6.8259e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 228/250\n",
      "77/77 - 0s - loss: 6.8259e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 229/250\n",
      "77/77 - 0s - loss: 6.8259e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 230/250\n",
      "77/77 - 0s - loss: 6.3383e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 231/250\n",
      "77/77 - 0s - loss: 6.3383e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 232/250\n",
      "77/77 - 0s - loss: 4.8756e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 233/250\n",
      "77/77 - 0s - loss: 4.8756e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 234/250\n",
      "77/77 - 1s - loss: 4.8756e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 235/250\n",
      "77/77 - 1s - loss: 3.9005e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 236/250\n",
      "77/77 - 0s - loss: 3.9005e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 237/250\n",
      "77/77 - 0s - loss: 3.4129e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 238/250\n",
      "77/77 - 0s - loss: 3.4129e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 239/250\n",
      "77/77 - 0s - loss: 3.4129e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 240/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 241/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 242/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 243/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 244/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 245/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 246/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 247/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 248/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 249/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 250/250\n",
      "77/77 - 0s - loss: 2.4378e-10 - precision: 1.0000 - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f943efaa710>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 - 0s - loss: 2.8022 - precision: 0.9031 - recall: 0.9031\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-113d6f0d4daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_loss, model_accuracy = deep_model.evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     X_test_scaled, y_test_categorical, verbose=2)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acuracy 0.87\n",
    "#Precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = deep_model.predict(X_test)\n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "predictions_categorical = predictions.astype(int)\n",
    "\n",
    "predictions = np.argmax(predictions_categorical, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y_test\n",
    "labels = labels.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(815,)\n",
      "(815,)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4082090748757415\n",
      "0.5388700409560486\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(recall))\n",
    "print(np.mean(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.56      0.22      0.32        99\n",
      "     class 1       0.89      0.98      0.93       702\n",
      "     class 2       0.00      0.00      0.00        14\n",
      "\n",
      "    accuracy                           0.87       815\n",
      "   macro avg       0.48      0.40      0.42       815\n",
      "weighted avg       0.83      0.87      0.84       815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = labels\n",
    "y_pred = predictions\n",
    "target_names = ['class 0', 'class 1', 'class 2']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP CLASS 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a1c</th>\n",
       "      <th>glucose</th>\n",
       "      <th>alb_cr_ratio</th>\n",
       "      <th>t_chol</th>\n",
       "      <th>trigs</th>\n",
       "      <th>platelets</th>\n",
       "      <th>grip_strength</th>\n",
       "      <th>ldh</th>\n",
       "      <th>cr</th>\n",
       "      <th>alk_phos</th>\n",
       "      <th>...</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>gen_health</th>\n",
       "      <th>phos</th>\n",
       "      <th>s_cotinine</th>\n",
       "      <th>chloride</th>\n",
       "      <th>t_bilirubin</th>\n",
       "      <th>bmi_group</th>\n",
       "      <th>age_group</th>\n",
       "      <th>bp_group</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.77</td>\n",
       "      <td>118.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>50.3</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>44.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.654</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.2</td>\n",
       "      <td>81.0</td>\n",
       "      <td>2.37</td>\n",
       "      <td>172.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>90.1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>112.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.221</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3.73</td>\n",
       "      <td>168.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>103.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.011</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>144.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>65.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>16.300</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.13</td>\n",
       "      <td>104.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>306.0</td>\n",
       "      <td>94.4</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>212.000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5196</th>\n",
       "      <td>5.8</td>\n",
       "      <td>98.0</td>\n",
       "      <td>49.63</td>\n",
       "      <td>185.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>47.2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.011</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>6.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.40</td>\n",
       "      <td>166.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>75.6</td>\n",
       "      <td>163.0</td>\n",
       "      <td>1.15</td>\n",
       "      <td>49.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5199</th>\n",
       "      <td>7.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>187.41</td>\n",
       "      <td>176.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>84.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.011</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>6.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>11.43</td>\n",
       "      <td>171.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>65.2</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.269</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>6.2</td>\n",
       "      <td>103.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>45.2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.035</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3182 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a1c  glucose  alb_cr_ratio  t_chol  trigs  platelets  grip_strength  \\\n",
       "0     5.0     82.0         11.77   118.0   54.0      157.0           50.3   \n",
       "1     5.2     81.0          2.37   172.0   83.0      226.0           90.1   \n",
       "2     5.1     87.0          3.73   168.0  256.0      266.0           72.7   \n",
       "3     5.1     91.0          3.74   144.0   57.0      206.0           86.6   \n",
       "4     6.0     89.0          3.13   104.0   70.0      306.0           94.4   \n",
       "...   ...      ...           ...     ...    ...        ...            ...   \n",
       "5196  5.8     98.0         49.63   185.0   80.0      178.0           47.2   \n",
       "5197  6.0    100.0          9.40   166.0  105.0      189.0           75.6   \n",
       "5199  7.0    175.0        187.41   176.0  104.0      273.0           33.1   \n",
       "5201  6.5    126.0         11.43   171.0  130.0      205.0           65.2   \n",
       "5204  6.2    103.0          3.92   181.0   67.0      213.0           45.2   \n",
       "\n",
       "        ldh    cr  alk_phos  ...  hypertension  gen_health  phos  s_cotinine  \\\n",
       "0      75.0  0.44      44.0  ...           2.0         3.0   4.2       0.654   \n",
       "1     137.0  0.81     112.0  ...           2.0         3.0   3.8       0.221   \n",
       "2     112.0  0.82     103.0  ...           2.0         3.0   4.4       0.011   \n",
       "3      87.0  0.73      65.0  ...           2.0         4.0   4.2      16.300   \n",
       "4     104.0  1.07      55.0  ...           2.0         2.0   4.3     212.000   \n",
       "...     ...   ...       ...  ...           ...         ...   ...         ...   \n",
       "5196  127.0  0.55      42.0  ...           1.0         3.0   3.7       0.011   \n",
       "5197  163.0  1.15      49.0  ...           2.0         3.0   3.0       0.011   \n",
       "5199  155.0  0.92      84.0  ...           1.0         3.0   3.9       0.011   \n",
       "5201  119.0  0.73      50.0  ...           2.0         2.0   3.1       0.269   \n",
       "5204  138.0  0.95      80.0  ...           1.0         3.0   3.5       0.035   \n",
       "\n",
       "      chloride  t_bilirubin  bmi_group  age_group  bp_group  diabetes  \n",
       "0        105.0          0.8          0          1         0       1.0  \n",
       "1        102.0          1.2          1          1         0       1.0  \n",
       "2        104.0          0.4          1          1         0       1.0  \n",
       "3        102.0          0.9          0          1         0       1.0  \n",
       "4        104.0          0.8          2          1         2       1.0  \n",
       "...        ...          ...        ...        ...       ...       ...  \n",
       "5196     103.0          0.9          0          4         2       1.0  \n",
       "5197     105.0          1.0          1          4         2       1.0  \n",
       "5199     102.0          0.5          2          4         2       0.0  \n",
       "5201     107.0          0.7          2          4         2       0.0  \n",
       "5204     103.0          1.0          2          4         1       0.0  \n",
       "\n",
       "[3182 rows x 35 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df2 = diab_df[diab_df.diabetes != 2.0]\n",
    "diab_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_df4 = diab_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2792\n",
       "1.0     390\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert DIAABETES VALUES 0->1 AND 1->0\n",
    "\n",
    "diab_df4['diabetes'] = diab_df4['diabetes'].replace([0,1],[1,0])\n",
    "diab_df4['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = diab_df4.drop(\"diabetes\", axis=1) \n",
    "feature_names4 = data4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "target4 = diab_df4[\"diabetes\"].values.reshape(-1, 1)\n",
    "target_names4 = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of variables is: 34\n"
     ]
    }
   ],
   "source": [
    "numb_variables =len(feature_names.tolist())\n",
    "print(f\"The total number of variables is: {numb_variables}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data4, target4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1432, 34)\n",
      "(1432, 1)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.layers import Flatten, Dense, Reshape\n",
    "oversample = SMOTE()\n",
    "X_test, y_test = oversample.fit_resample(X_test, y_test)\n",
    "\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEEPLEARNING\n",
    "#y_predict = model.predict(X_test) \n",
    "#y_predict = (y_predict>0.25) # It will evaluate the logical expression y_predict>0.25 and return True or False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Recall at 0x7f9447c26470>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=102, activation='relu', input_dim=34))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "\n",
    "deep_model.add(Dense(units=102, activation='relu'))\n",
    "\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"Recall\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "75/75 - 0s - loss: 1.0492e-09 - recall: 1.0000\n",
      "Epoch 2/175\n",
      "75/75 - 0s - loss: 3.9970e-09 - recall: 1.0000\n",
      "Epoch 3/175\n",
      "75/75 - 1s - loss: 0.4047 - recall: 0.9371\n",
      "Epoch 4/175\n",
      "75/75 - 0s - loss: 0.0938 - recall: 0.9648\n",
      "Epoch 5/175\n",
      "75/75 - 0s - loss: 0.0530 - recall: 0.9786\n",
      "Epoch 6/175\n",
      "75/75 - 0s - loss: 0.0221 - recall: 0.9933\n",
      "Epoch 7/175\n",
      "75/75 - 1s - loss: 0.0209 - recall: 0.9920\n",
      "Epoch 8/175\n",
      "75/75 - 0s - loss: 0.0249 - recall: 0.9916\n",
      "Epoch 9/175\n",
      "75/75 - 0s - loss: 0.0325 - recall: 0.9887\n",
      "Epoch 10/175\n",
      "75/75 - 0s - loss: 0.0172 - recall: 0.9958\n",
      "Epoch 11/175\n",
      "75/75 - 1s - loss: 0.0075 - recall: 0.9975\n",
      "Epoch 12/175\n",
      "75/75 - 0s - loss: 0.0110 - recall: 0.9987\n",
      "Epoch 13/175\n",
      "75/75 - 0s - loss: 0.0103 - recall: 0.9966\n",
      "Epoch 14/175\n",
      "75/75 - 0s - loss: 0.0523 - recall: 0.9870\n",
      "Epoch 15/175\n",
      "75/75 - 1s - loss: 0.0302 - recall: 0.9908\n",
      "Epoch 16/175\n",
      "75/75 - 0s - loss: 0.0252 - recall: 0.9916\n",
      "Epoch 17/175\n",
      "75/75 - 0s - loss: 0.0257 - recall: 0.9920\n",
      "Epoch 18/175\n",
      "75/75 - 0s - loss: 0.0192 - recall: 0.9920\n",
      "Epoch 19/175\n",
      "75/75 - 0s - loss: 0.0108 - recall: 0.9966\n",
      "Epoch 20/175\n",
      "75/75 - 0s - loss: 0.0092 - recall: 0.9971\n",
      "Epoch 21/175\n",
      "75/75 - 1s - loss: 0.0061 - recall: 0.9975\n",
      "Epoch 22/175\n",
      "75/75 - 1s - loss: 6.1414e-04 - recall: 1.0000\n",
      "Epoch 23/175\n",
      "75/75 - 0s - loss: 1.8240e-04 - recall: 1.0000\n",
      "Epoch 24/175\n",
      "75/75 - 0s - loss: 1.0296e-04 - recall: 1.0000\n",
      "Epoch 25/175\n",
      "75/75 - 0s - loss: 7.3151e-05 - recall: 1.0000\n",
      "Epoch 26/175\n",
      "75/75 - 0s - loss: 5.2887e-05 - recall: 1.0000\n",
      "Epoch 27/175\n",
      "75/75 - 0s - loss: 3.3395e-05 - recall: 1.0000\n",
      "Epoch 28/175\n",
      "75/75 - 0s - loss: 1.9587e-05 - recall: 1.0000\n",
      "Epoch 29/175\n",
      "75/75 - 0s - loss: 1.3379e-05 - recall: 1.0000\n",
      "Epoch 30/175\n",
      "75/75 - 0s - loss: 1.0112e-05 - recall: 1.0000\n",
      "Epoch 31/175\n",
      "75/75 - 0s - loss: 8.2435e-06 - recall: 1.0000\n",
      "Epoch 32/175\n",
      "75/75 - 0s - loss: 6.8374e-06 - recall: 1.0000\n",
      "Epoch 33/175\n",
      "75/75 - 0s - loss: 5.8634e-06 - recall: 1.0000\n",
      "Epoch 34/175\n",
      "75/75 - 0s - loss: 5.1660e-06 - recall: 1.0000\n",
      "Epoch 35/175\n",
      "75/75 - 0s - loss: 4.6331e-06 - recall: 1.0000\n",
      "Epoch 36/175\n",
      "75/75 - 0s - loss: 4.1634e-06 - recall: 1.0000\n",
      "Epoch 37/175\n",
      "75/75 - 0s - loss: 3.7834e-06 - recall: 1.0000\n",
      "Epoch 38/175\n",
      "75/75 - 0s - loss: 3.4570e-06 - recall: 1.0000\n",
      "Epoch 39/175\n",
      "75/75 - 0s - loss: 3.2030e-06 - recall: 1.0000\n",
      "Epoch 40/175\n",
      "75/75 - 0s - loss: 3.0437e-06 - recall: 1.0000\n",
      "Epoch 41/175\n",
      "75/75 - 0s - loss: 2.7890e-06 - recall: 1.0000\n",
      "Epoch 42/175\n",
      "75/75 - 0s - loss: 2.5956e-06 - recall: 1.0000\n",
      "Epoch 43/175\n",
      "75/75 - 0s - loss: 2.4521e-06 - recall: 1.0000\n",
      "Epoch 44/175\n",
      "75/75 - 0s - loss: 2.2946e-06 - recall: 1.0000\n",
      "Epoch 45/175\n",
      "75/75 - 0s - loss: 2.1637e-06 - recall: 1.0000\n",
      "Epoch 46/175\n",
      "75/75 - 0s - loss: 2.1015e-06 - recall: 1.0000\n",
      "Epoch 47/175\n",
      "75/75 - 0s - loss: 1.9271e-06 - recall: 1.0000\n",
      "Epoch 48/175\n",
      "75/75 - 0s - loss: 1.8322e-06 - recall: 1.0000\n",
      "Epoch 49/175\n",
      "75/75 - 0s - loss: 1.7574e-06 - recall: 1.0000\n",
      "Epoch 50/175\n",
      "75/75 - 0s - loss: 1.6957e-06 - recall: 1.0000\n",
      "Epoch 51/175\n",
      "75/75 - 0s - loss: 1.5957e-06 - recall: 1.0000\n",
      "Epoch 52/175\n",
      "75/75 - 0s - loss: 1.5030e-06 - recall: 1.0000\n",
      "Epoch 53/175\n",
      "75/75 - 0s - loss: 1.4234e-06 - recall: 1.0000\n",
      "Epoch 54/175\n",
      "75/75 - 0s - loss: 1.4169e-06 - recall: 1.0000\n",
      "Epoch 55/175\n",
      "75/75 - 0s - loss: 1.3064e-06 - recall: 1.0000\n",
      "Epoch 56/175\n",
      "75/75 - 1s - loss: 1.2558e-06 - recall: 1.0000\n",
      "Epoch 57/175\n",
      "75/75 - 0s - loss: 1.1935e-06 - recall: 1.0000\n",
      "Epoch 58/175\n",
      "75/75 - 0s - loss: 1.1286e-06 - recall: 1.0000\n",
      "Epoch 59/175\n",
      "75/75 - 0s - loss: 1.0865e-06 - recall: 1.0000\n",
      "Epoch 60/175\n",
      "75/75 - 0s - loss: 1.0347e-06 - recall: 1.0000\n",
      "Epoch 61/175\n",
      "75/75 - 0s - loss: 1.0009e-06 - recall: 1.0000\n",
      "Epoch 62/175\n",
      "75/75 - 0s - loss: 9.4620e-07 - recall: 1.0000\n",
      "Epoch 63/175\n",
      "75/75 - 0s - loss: 9.1188e-07 - recall: 1.0000\n",
      "Epoch 64/175\n",
      "75/75 - 0s - loss: 8.7796e-07 - recall: 1.0000\n",
      "Epoch 65/175\n",
      "75/75 - 0s - loss: 8.3280e-07 - recall: 1.0000\n",
      "Epoch 66/175\n",
      "75/75 - 0s - loss: 8.0892e-07 - recall: 1.0000\n",
      "Epoch 67/175\n",
      "75/75 - 0s - loss: 7.8104e-07 - recall: 1.0000\n",
      "Epoch 68/175\n",
      "75/75 - 0s - loss: 7.4906e-07 - recall: 1.0000\n",
      "Epoch 69/175\n",
      "75/75 - 0s - loss: 7.1589e-07 - recall: 1.0000\n",
      "Epoch 70/175\n",
      "75/75 - 0s - loss: 6.9611e-07 - recall: 1.0000\n",
      "Epoch 71/175\n",
      "75/75 - 0s - loss: 6.6838e-07 - recall: 1.0000\n",
      "Epoch 72/175\n",
      "75/75 - 0s - loss: 6.2966e-07 - recall: 1.0000\n",
      "Epoch 73/175\n",
      "75/75 - 0s - loss: 6.1337e-07 - recall: 1.0000\n",
      "Epoch 74/175\n",
      "75/75 - 0s - loss: 5.7350e-07 - recall: 1.0000\n",
      "Epoch 75/175\n",
      "75/75 - 0s - loss: 5.6201e-07 - recall: 1.0000\n",
      "Epoch 76/175\n",
      "75/75 - 0s - loss: 5.3423e-07 - recall: 1.0000\n",
      "Epoch 77/175\n",
      "75/75 - 0s - loss: 5.0926e-07 - recall: 1.0000\n",
      "Epoch 78/175\n",
      "75/75 - 0s - loss: 4.8557e-07 - recall: 1.0000\n",
      "Epoch 79/175\n",
      "75/75 - 0s - loss: 4.7843e-07 - recall: 1.0000\n",
      "Epoch 80/175\n",
      "75/75 - 0s - loss: 4.5295e-07 - recall: 1.0000\n",
      "Epoch 81/175\n",
      "75/75 - 0s - loss: 4.3551e-07 - recall: 1.0000\n",
      "Epoch 82/175\n",
      "75/75 - 0s - loss: 4.1533e-07 - recall: 1.0000\n",
      "Epoch 83/175\n",
      "75/75 - 0s - loss: 4.0454e-07 - recall: 1.0000\n",
      "Epoch 84/175\n",
      "75/75 - 0s - loss: 3.9095e-07 - recall: 1.0000\n",
      "Epoch 85/175\n",
      "75/75 - 0s - loss: 3.6986e-07 - recall: 1.0000\n",
      "Epoch 86/175\n",
      "75/75 - 0s - loss: 3.5288e-07 - recall: 1.0000\n",
      "Epoch 87/175\n",
      "75/75 - 0s - loss: 3.3879e-07 - recall: 1.0000\n",
      "Epoch 88/175\n",
      "75/75 - 0s - loss: 3.2930e-07 - recall: 1.0000\n",
      "Epoch 89/175\n",
      "75/75 - 0s - loss: 3.1626e-07 - recall: 1.0000\n",
      "Epoch 90/175\n",
      "75/75 - 0s - loss: 3.0397e-07 - recall: 1.0000\n",
      "Epoch 91/175\n",
      "75/75 - 0s - loss: 2.9108e-07 - recall: 1.0000\n",
      "Epoch 92/175\n",
      "75/75 - 0s - loss: 2.7924e-07 - recall: 1.0000\n",
      "Epoch 93/175\n",
      "75/75 - 0s - loss: 2.7049e-07 - recall: 1.0000\n",
      "Epoch 94/175\n",
      "75/75 - 0s - loss: 2.5805e-07 - recall: 1.0000\n",
      "Epoch 95/175\n",
      "75/75 - 0s - loss: 2.4866e-07 - recall: 1.0000\n",
      "Epoch 96/175\n",
      "75/75 - 0s - loss: 2.3967e-07 - recall: 1.0000\n",
      "Epoch 97/175\n",
      "75/75 - 0s - loss: 2.2803e-07 - recall: 1.0000\n",
      "Epoch 98/175\n",
      "75/75 - 0s - loss: 2.1823e-07 - recall: 1.0000\n",
      "Epoch 99/175\n",
      "75/75 - 0s - loss: 2.0984e-07 - recall: 1.0000\n",
      "Epoch 100/175\n",
      "75/75 - 0s - loss: 2.0239e-07 - recall: 1.0000\n",
      "Epoch 101/175\n",
      "75/75 - 1s - loss: 1.9370e-07 - recall: 1.0000\n",
      "Epoch 102/175\n",
      "75/75 - 1s - loss: 1.8706e-07 - recall: 1.0000\n",
      "Epoch 103/175\n",
      "75/75 - 0s - loss: 1.8026e-07 - recall: 1.0000\n",
      "Epoch 104/175\n",
      "75/75 - 0s - loss: 1.7252e-07 - recall: 1.0000\n",
      "Epoch 105/175\n",
      "75/75 - 0s - loss: 1.6552e-07 - recall: 1.0000\n",
      "Epoch 106/175\n",
      "75/75 - 0s - loss: 1.5948e-07 - recall: 1.0000\n",
      "Epoch 107/175\n",
      "75/75 - 0s - loss: 1.5413e-07 - recall: 1.0000\n",
      "Epoch 108/175\n",
      "75/75 - 0s - loss: 1.4724e-07 - recall: 1.0000\n",
      "Epoch 109/175\n",
      "75/75 - 0s - loss: 1.4029e-07 - recall: 1.0000\n",
      "Epoch 110/175\n",
      "75/75 - 0s - loss: 1.3500e-07 - recall: 1.0000\n",
      "Epoch 111/175\n",
      "75/75 - 0s - loss: 1.2905e-07 - recall: 1.0000\n",
      "Epoch 112/175\n",
      "75/75 - 0s - loss: 1.2555e-07 - recall: 1.0000\n",
      "Epoch 113/175\n",
      "75/75 - 0s - loss: 1.2006e-07 - recall: 1.0000\n",
      "Epoch 114/175\n",
      "75/75 - 1s - loss: 1.1591e-07 - recall: 1.0000\n",
      "Epoch 115/175\n",
      "75/75 - 0s - loss: 1.1321e-07 - recall: 1.0000\n",
      "Epoch 116/175\n",
      "75/75 - 1s - loss: 1.0762e-07 - recall: 1.0000\n",
      "Epoch 117/175\n",
      "75/75 - 0s - loss: 1.0167e-07 - recall: 1.0000\n",
      "Epoch 118/175\n",
      "75/75 - 0s - loss: 9.8425e-08 - recall: 1.0000\n",
      "Epoch 119/175\n",
      "75/75 - 0s - loss: 9.4328e-08 - recall: 1.0000\n",
      "Epoch 120/175\n",
      "75/75 - 0s - loss: 9.1280e-08 - recall: 1.0000\n",
      "Epoch 121/175\n",
      "75/75 - 0s - loss: 8.6784e-08 - recall: 1.0000\n",
      "Epoch 122/175\n",
      "75/75 - 0s - loss: 8.3686e-08 - recall: 1.0000\n",
      "Epoch 123/175\n",
      "75/75 - 0s - loss: 8.1088e-08 - recall: 1.0000\n",
      "Epoch 124/175\n",
      "75/75 - 0s - loss: 7.7941e-08 - recall: 1.0000\n",
      "Epoch 125/175\n",
      "75/75 - 0s - loss: 7.4893e-08 - recall: 1.0000\n",
      "Epoch 126/175\n",
      "75/75 - 0s - loss: 7.1096e-08 - recall: 1.0000\n",
      "Epoch 127/175\n",
      "75/75 - 0s - loss: 6.8248e-08 - recall: 1.0000\n",
      "Epoch 128/175\n",
      "75/75 - 0s - loss: 6.5700e-08 - recall: 1.0000\n",
      "Epoch 129/175\n",
      "75/75 - 0s - loss: 6.3002e-08 - recall: 1.0000\n",
      "Epoch 130/175\n",
      "75/75 - 0s - loss: 6.0904e-08 - recall: 1.0000\n",
      "Epoch 131/175\n",
      "75/75 - 0s - loss: 5.7906e-08 - recall: 1.0000\n",
      "Epoch 132/175\n",
      "75/75 - 0s - loss: 5.5857e-08 - recall: 1.0000\n",
      "Epoch 133/175\n",
      "75/75 - 0s - loss: 5.4908e-08 - recall: 1.0000\n",
      "Epoch 134/175\n",
      "75/75 - 0s - loss: 5.0811e-08 - recall: 1.0000\n",
      "Epoch 135/175\n",
      "75/75 - 0s - loss: 4.9562e-08 - recall: 1.0000\n",
      "Epoch 136/175\n",
      "75/75 - 0s - loss: 4.7564e-08 - recall: 1.0000\n",
      "Epoch 137/175\n",
      "75/75 - 0s - loss: 4.5365e-08 - recall: 1.0000\n",
      "Epoch 138/175\n",
      "75/75 - 0s - loss: 4.3667e-08 - recall: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/175\n",
      "75/75 - 0s - loss: 4.2118e-08 - recall: 1.0000\n",
      "Epoch 140/175\n",
      "75/75 - 0s - loss: 4.0169e-08 - recall: 1.0000\n",
      "Epoch 141/175\n",
      "75/75 - 0s - loss: 3.8521e-08 - recall: 1.0000\n",
      "Epoch 142/175\n",
      "75/75 - 1s - loss: 3.7322e-08 - recall: 1.0000\n",
      "Epoch 143/175\n",
      "75/75 - 1s - loss: 3.5973e-08 - recall: 1.0000\n",
      "Epoch 144/175\n",
      "75/75 - 0s - loss: 3.4823e-08 - recall: 1.0000\n",
      "Epoch 145/175\n",
      "75/75 - 0s - loss: 3.3724e-08 - recall: 1.0000\n",
      "Epoch 146/175\n",
      "75/75 - 0s - loss: 3.2126e-08 - recall: 1.0000\n",
      "Epoch 147/175\n",
      "75/75 - 0s - loss: 3.0827e-08 - recall: 1.0000\n",
      "Epoch 148/175\n",
      "75/75 - 0s - loss: 2.9677e-08 - recall: 1.0000\n",
      "Epoch 149/175\n",
      "75/75 - 0s - loss: 2.7929e-08 - recall: 1.0000\n",
      "Epoch 150/175\n",
      "75/75 - 0s - loss: 2.7229e-08 - recall: 1.0000\n",
      "Epoch 151/175\n",
      "75/75 - 0s - loss: 2.5930e-08 - recall: 1.0000\n",
      "Epoch 152/175\n",
      "75/75 - 0s - loss: 2.4831e-08 - recall: 1.0000\n",
      "Epoch 153/175\n",
      "75/75 - 0s - loss: 2.3882e-08 - recall: 1.0000\n",
      "Epoch 154/175\n",
      "75/75 - 0s - loss: 2.3032e-08 - recall: 1.0000\n",
      "Epoch 155/175\n",
      "75/75 - 0s - loss: 2.1983e-08 - recall: 1.0000\n",
      "Epoch 156/175\n",
      "75/75 - 0s - loss: 2.0984e-08 - recall: 1.0000\n",
      "Epoch 157/175\n",
      "75/75 - 0s - loss: 2.0534e-08 - recall: 1.0000\n",
      "Epoch 158/175\n",
      "75/75 - 0s - loss: 1.9485e-08 - recall: 1.0000\n",
      "Epoch 159/175\n",
      "75/75 - 0s - loss: 1.8686e-08 - recall: 1.0000\n",
      "Epoch 160/175\n",
      "75/75 - 0s - loss: 1.8286e-08 - recall: 1.0000\n",
      "Epoch 161/175\n",
      "75/75 - 0s - loss: 1.7137e-08 - recall: 1.0000\n",
      "Epoch 162/175\n",
      "75/75 - 0s - loss: 1.6587e-08 - recall: 1.0000\n",
      "Epoch 163/175\n",
      "75/75 - 0s - loss: 1.5938e-08 - recall: 1.0000\n",
      "Epoch 164/175\n",
      "75/75 - 0s - loss: 1.5188e-08 - recall: 1.0000\n",
      "Epoch 165/175\n",
      "75/75 - 0s - loss: 1.4439e-08 - recall: 1.0000\n",
      "Epoch 166/175\n",
      "75/75 - 0s - loss: 1.4039e-08 - recall: 1.0000\n",
      "Epoch 167/175\n",
      "75/75 - 0s - loss: 1.3640e-08 - recall: 1.0000\n",
      "Epoch 168/175\n",
      "75/75 - 0s - loss: 1.2890e-08 - recall: 1.0000\n",
      "Epoch 169/175\n",
      "75/75 - 0s - loss: 1.2540e-08 - recall: 1.0000\n",
      "Epoch 170/175\n",
      "75/75 - 0s - loss: 1.2191e-08 - recall: 1.0000\n",
      "Epoch 171/175\n",
      "75/75 - 0s - loss: 1.1691e-08 - recall: 1.0000\n",
      "Epoch 172/175\n",
      "75/75 - 0s - loss: 1.1241e-08 - recall: 1.0000\n",
      "Epoch 173/175\n",
      "75/75 - 0s - loss: 1.0892e-08 - recall: 1.0000\n",
      "Epoch 174/175\n",
      "75/75 - 0s - loss: 1.0442e-08 - recall: 1.0000\n",
      "Epoch 175/175\n",
      "75/75 - 0s - loss: 9.9424e-09 - recall: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f943a705d30>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=175,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 1.4759 - recall: 0.9334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.475947380065918, 0.9334170818328857]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 0s - loss: 1.4759 - recall: 0.9334\n",
      "Deep Neural Network - Loss: 1.475947380065918,  Recall: 0.9334170818328857 \n"
     ]
    }
   ],
   "source": [
    "model_loss, model_recall = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss},  Recall: {model_recall} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = deep_model.predict(X_test)\n",
    "predictions_categorical = predictions.astype(int)\n",
    "predictions = np.argmax(predictions_categorical, axis=-1)\n",
    "\n",
    "#predictions = deep_model.predict(X_test) \n",
    "#predictions = (predictions>0.25) # It will evaluate the logical expression y_predict>0.25 and return True or False\n",
    "#predictions_categorical = predictions.astype(int)\n",
    "#predictions = np.argmax(predictions_categorical, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = y_test\n",
    "labels = labels.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.90      1.00      0.95       716\n",
      "Has Diabetes       0.40      0.03      0.05        80\n",
      "\n",
      "    accuracy                           0.90       796\n",
      "   macro avg       0.65      0.51      0.50       796\n",
      "weighted avg       0.85      0.90      0.86       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = labels\n",
    "y_pred = predictions\n",
    "target_names = [\"No Diabetes\", \"Has Diabetes\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model.save(\"diabetes_deeplearning.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_df3 = diab_df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2792\n",
       "1.0     390\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert DIAABETES VALUES 0->1 AND 1->0\n",
    "\n",
    "diab_df3['diabetes'] = diab_df3['diabetes'].replace([0,1],[1,0])\n",
    "diab_df3['diabetes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = diab_df3.drop(\"diabetes\", axis=1) \n",
    "feature_names3 = data3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "target3 = diab_df3[\"diabetes\"].values.reshape(-1, 1)\n",
    "target_names3 = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3182, 34)\n",
      "(3182, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data3.shape)\n",
    "print(target3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data3, target3, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 75, 100],\n",
    "             # 'kernel':[\"linear\", \"rbf\",\"poly\"],\n",
    "              'gamma': [ 0.001, 0.005, 0.01, 0.05]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3, scoring = 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.613, total=   0.4s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.565, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.581, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.001, score=0.629, total=   0.2s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.532, total=   0.2s\n",
      "[CV] C=1, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.005, score=0.613, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.565, total=   0.2s\n",
      "[CV] C=1, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.005, score=0.581, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.629, total=   0.1s\n",
      "[CV] C=1, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=1, gamma=0.005, score=0.532, total=   0.3s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.613, total=   0.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.01, score=0.565, total=   0.4s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.581, total=   0.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.01, score=0.629, total=   0.2s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] ..................... C=1, gamma=0.01, score=0.532, total=   0.2s\n",
      "[CV] C=1, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.05, score=0.613, total=   0.5s\n",
      "[CV] C=1, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.05, score=0.565, total=   1.2s\n",
      "[CV] C=1, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.05, score=0.581, total=   0.5s\n",
      "[CV] C=1, gamma=0.05 .................................................\n",
      "[CV] ..................... C=1, gamma=0.05, score=0.629, total=   0.1s\n",
      "[CV] C=1, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=1, gamma=0.05, score=0.532, total=   0.2s\n",
      "[CV] C=5, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.001, score=0.613, total=   0.8s\n",
      "[CV] C=5, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.001, score=0.565, total=   0.8s\n",
      "[CV] C=5, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.001, score=0.581, total=   0.7s\n",
      "[CV] C=5, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.001, score=0.629, total=   0.6s\n",
      "[CV] C=5, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.001, score=0.548, total=   0.7s\n",
      "[CV] C=5, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.005, score=0.613, total=   0.7s\n",
      "[CV] C=5, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.005, score=0.565, total=   0.8s\n",
      "[CV] C=5, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.005, score=0.581, total=   1.1s\n",
      "[CV] C=5, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.005, score=0.629, total=   0.6s\n",
      "[CV] C=5, gamma=0.005 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=5, gamma=0.005, score=0.548, total=   0.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.01, score=0.613, total=   0.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.01, score=0.565, total=   0.7s\n",
      "[CV] C=5, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.01, score=0.581, total=   1.4s\n",
      "[CV] C=5, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.01, score=0.629, total=   1.5s\n",
      "[CV] C=5, gamma=0.01 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.01, score=0.548, total=   4.0s\n",
      "[CV] C=5, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.05, score=0.613, total=   2.8s\n",
      "[CV] C=5, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.05, score=0.565, total=   1.8s\n",
      "[CV] C=5, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.05, score=0.581, total=   3.1s\n",
      "[CV] C=5, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.05, score=0.629, total=   1.5s\n",
      "[CV] C=5, gamma=0.05 .................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................... C=5, gamma=0.05, score=0.548, total=   1.1s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.613, total=   1.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.565, total=   4.8s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.581, total=   3.2s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.629, total=   3.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.001, score=0.565, total=   1.3s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.005, score=0.613, total=   1.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.005, score=0.565, total=   1.2s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.005, score=0.581, total=   2.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.005, score=0.629, total=   1.0s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=10, gamma=0.005, score=0.565, total=   1.1s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.01, score=0.613, total=   0.9s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.01, score=0.565, total=   1.2s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.01, score=0.581, total=   1.2s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.01, score=0.629, total=   1.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.01, score=0.565, total=   1.2s\n",
      "[CV] C=10, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.05, score=0.613, total=   0.9s\n",
      "[CV] C=10, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.05, score=0.565, total=   1.2s\n",
      "[CV] C=10, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.05, score=0.581, total=   1.2s\n",
      "[CV] C=10, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.05, score=0.629, total=   1.1s\n",
      "[CV] C=10, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=10, gamma=0.05, score=0.565, total=   1.1s\n",
      "[CV] C=75, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.001, score=0.613, total=   7.8s\n",
      "[CV] C=75, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.001, score=0.565, total=  12.8s\n",
      "[CV] C=75, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.001, score=0.581, total=  17.3s\n",
      "[CV] C=75, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.001, score=0.629, total=   7.8s\n",
      "[CV] C=75, gamma=0.001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.001, score=0.548, total=   8.2s\n",
      "[CV] C=75, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.005, score=0.613, total=   8.9s\n",
      "[CV] C=75, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.005, score=0.565, total=  12.0s\n",
      "[CV] C=75, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.005, score=0.581, total=  11.3s\n",
      "[CV] C=75, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.005, score=0.629, total=   9.1s\n",
      "[CV] C=75, gamma=0.005 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=75, gamma=0.005, score=0.548, total=  18.6s\n",
      "[CV] C=75, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.01, score=0.613, total=  22.2s\n",
      "[CV] C=75, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.01, score=0.565, total=  20.8s\n",
      "[CV] C=75, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.01, score=0.581, total=  19.7s\n",
      "[CV] C=75, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.01, score=0.629, total=  13.4s\n",
      "[CV] C=75, gamma=0.01 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.01, score=0.548, total=  13.7s\n",
      "[CV] C=75, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.05, score=0.613, total=  18.0s\n",
      "[CV] C=75, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.05, score=0.565, total=  55.9s\n",
      "[CV] C=75, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.05, score=0.581, total=  19.4s\n",
      "[CV] C=75, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.05, score=0.629, total=   8.3s\n",
      "[CV] C=75, gamma=0.05 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... C=75, gamma=0.05, score=0.548, total=  30.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.001, score=0.613, total=  18.9s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.001, score=0.565, total=  15.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.001, score=0.581, total=  17.4s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.001, score=0.629, total=  13.1s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.001, score=0.548, total=  10.1s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.005, score=0.613, total=   8.3s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.005, score=0.565, total=  16.8s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.005, score=0.581, total=  18.6s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.005, score=0.629, total=  10.3s\n",
      "[CV] C=100, gamma=0.005 ..............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=100, gamma=0.005, score=0.548, total=  13.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.01, score=0.613, total=  12.8s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.01, score=0.565, total=  18.4s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.01, score=0.581, total=  23.2s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.01, score=0.629, total=  14.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.01, score=0.548, total=  19.0s\n",
      "[CV] C=100, gamma=0.05 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.05, score=0.613, total=  13.6s\n",
      "[CV] C=100, gamma=0.05 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.05, score=0.565, total=  16.7s\n",
      "[CV] C=100, gamma=0.05 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.05, score=0.581, total=  29.5s\n",
      "[CV] C=100, gamma=0.05 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.05, score=0.629, total=  11.1s\n",
      "[CV] C=100, gamma=0.05 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=100, gamma=0.05, score=0.548, total=  13.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed: 11.9min finished\n",
      "/Users/tajudeenadeyemi/opt/anaconda3/envs/PythonAdv/lib/python3.6/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 75, 100],\n",
       "                         'gamma': [0.001, 0.005, 0.01, 0.05]},\n",
       "             scoring='recall', verbose=3)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5903225806451613\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.96      0.99      0.97       716\n",
      "Has Diabetes       0.88      0.62      0.73        80\n",
      "\n",
      "    accuracy                           0.95       796\n",
      "   macro avg       0.92      0.81      0.85       796\n",
      "weighted avg       0.95      0.95      0.95       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"No Diabetes\", \"Has Diabetes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "pickle.dump(grid, open('Diabetes_svm.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('Diabetes_svm.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "        0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "        0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([[-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [ 2.58781263],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674],\n",
       "        [-0.38642674]]))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "predictions, y_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.96      0.99      0.97       716\n",
      "Has Diabetes       0.88      0.62      0.73        80\n",
      "\n",
      "    accuracy                           0.95       796\n",
      "   macro avg       0.92      0.81      0.85       796\n",
      "weighted avg       0.95      0.95      0.95       796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"No Diabetes\", \"Has Diabetes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing with alll columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_df6 = df2.copy()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2792\n",
       "1.0     390\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "diab_df6 = diab_df6[diab_df6.diabetes != 2.0]\n",
    "diab_df6['diabetes'] = diab_df6['diabetes'].replace([0,1],[1,0])\n",
    "diab_df6['diabetes'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "data6 = diab_df6.drop(\"diabetes\", axis=1) \n",
    "feature_names6 = data6.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "target6=diab_df6['diabetes'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of variables is: 58\n"
     ]
    }
   ],
   "source": [
    "numb_variables =len(feature_names6.tolist())\n",
    "print(f\"The total number of variables is: {numb_variables}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data6, target6, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1432, 58)\n",
      "(1432, 1)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_test, y_test = oversample.fit_resample(X_test, y_test)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)\n",
    "y_scaler = StandardScaler().fit(y_train)\n",
    "### BEGIN SOLUTION\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "y_train_scaled = y_scaler.transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_categorical = to_categorical(y_train)\n",
    "y_test_categorical = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.metrics.Recall at 0x7f9448ea98d0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=180, activation='relu', input_dim=58))\n",
    "deep_model.add(Dense(units=116, activation='relu'))\n",
    "deep_model.add(Dense(units=116, activation='relu'))\n",
    "deep_model.add(Dense(units=116, activation='relu'))\n",
    "deep_model.add(Dense(units=116, activation='relu'))\n",
    "deep_model.add(Dense(units=116, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "75/75 - 0s - loss: 0.3529 - accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "75/75 - 0s - loss: 0.2218 - accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "75/75 - 0s - loss: 0.1779 - accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "75/75 - 0s - loss: 0.1499 - accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "75/75 - 0s - loss: 0.1266 - accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "75/75 - 1s - loss: 0.1050 - accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "75/75 - 0s - loss: 0.0838 - accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "75/75 - 0s - loss: 0.0641 - accuracy: 4.1911e-04\n",
      "Epoch 9/150\n",
      "75/75 - 0s - loss: 0.0483 - accuracy: 0.0019\n",
      "Epoch 10/150\n",
      "75/75 - 0s - loss: 0.0340 - accuracy: 0.0065\n",
      "Epoch 11/150\n",
      "75/75 - 0s - loss: 0.0227 - accuracy: 0.0193\n",
      "Epoch 12/150\n",
      "75/75 - 0s - loss: 0.0135 - accuracy: 0.0348\n",
      "Epoch 13/150\n",
      "75/75 - 0s - loss: 0.0085 - accuracy: 0.0616\n",
      "Epoch 14/150\n",
      "75/75 - 0s - loss: 0.0061 - accuracy: 0.0792\n",
      "Epoch 15/150\n",
      "75/75 - 0s - loss: 0.0034 - accuracy: 0.1102\n",
      "Epoch 16/150\n",
      "75/75 - 0s - loss: 0.0016 - accuracy: 0.1312\n",
      "Epoch 17/150\n",
      "75/75 - 0s - loss: 0.0010 - accuracy: 0.1572\n",
      "Epoch 18/150\n",
      "75/75 - 0s - loss: 7.1533e-04 - accuracy: 0.1758\n",
      "Epoch 19/150\n",
      "75/75 - 1s - loss: 5.3953e-04 - accuracy: 0.1949\n",
      "Epoch 20/150\n",
      "75/75 - 1s - loss: 4.2495e-04 - accuracy: 0.2068\n",
      "Epoch 21/150\n",
      "75/75 - 0s - loss: 3.2952e-04 - accuracy: 0.2207\n",
      "Epoch 22/150\n",
      "75/75 - 0s - loss: 2.7358e-04 - accuracy: 0.2332\n",
      "Epoch 23/150\n",
      "75/75 - 0s - loss: 2.2050e-04 - accuracy: 0.2393\n",
      "Epoch 24/150\n",
      "75/75 - 0s - loss: 1.8185e-04 - accuracy: 0.2487\n",
      "Epoch 25/150\n",
      "75/75 - 0s - loss: 1.5785e-04 - accuracy: 0.2582\n",
      "Epoch 26/150\n",
      "75/75 - 0s - loss: 1.3155e-04 - accuracy: 0.2632\n",
      "Epoch 27/150\n",
      "75/75 - 1s - loss: 1.1084e-04 - accuracy: 0.2710\n",
      "Epoch 28/150\n",
      "75/75 - 0s - loss: 9.6544e-05 - accuracy: 0.2768\n",
      "Epoch 29/150\n",
      "75/75 - 0s - loss: 8.3139e-05 - accuracy: 0.2831\n",
      "Epoch 30/150\n",
      "75/75 - 0s - loss: 7.1752e-05 - accuracy: 0.2894\n",
      "Epoch 31/150\n",
      "75/75 - 0s - loss: 6.2875e-05 - accuracy: 0.2909\n",
      "Epoch 32/150\n",
      "75/75 - 0s - loss: 5.4749e-05 - accuracy: 0.2963\n",
      "Epoch 33/150\n",
      "75/75 - 0s - loss: 4.7778e-05 - accuracy: 0.2990\n",
      "Epoch 34/150\n",
      "75/75 - 0s - loss: 4.2058e-05 - accuracy: 0.3034\n",
      "Epoch 35/150\n",
      "75/75 - 0s - loss: 3.7092e-05 - accuracy: 0.3087\n",
      "Epoch 36/150\n",
      "75/75 - 0s - loss: 3.2875e-05 - accuracy: 0.3127\n",
      "Epoch 37/150\n",
      "75/75 - 0s - loss: 2.8801e-05 - accuracy: 0.3164\n",
      "Epoch 38/150\n",
      "75/75 - 0s - loss: 2.5533e-05 - accuracy: 0.3238\n",
      "Epoch 39/150\n",
      "75/75 - 0s - loss: 2.2640e-05 - accuracy: 0.3265\n",
      "Epoch 40/150\n",
      "75/75 - 0s - loss: 2.0210e-05 - accuracy: 0.3301\n",
      "Epoch 41/150\n",
      "75/75 - 0s - loss: 1.8019e-05 - accuracy: 0.3321\n",
      "Epoch 42/150\n",
      "75/75 - 0s - loss: 1.5980e-05 - accuracy: 0.3361\n",
      "Epoch 43/150\n",
      "75/75 - 0s - loss: 1.4315e-05 - accuracy: 0.3395\n",
      "Epoch 44/150\n",
      "75/75 - 0s - loss: 1.2770e-05 - accuracy: 0.3420\n",
      "Epoch 45/150\n",
      "75/75 - 0s - loss: 1.1450e-05 - accuracy: 0.3458\n",
      "Epoch 46/150\n",
      "75/75 - 0s - loss: 1.0270e-05 - accuracy: 0.3489\n",
      "Epoch 47/150\n",
      "75/75 - 0s - loss: 9.1848e-06 - accuracy: 0.3516\n",
      "Epoch 48/150\n",
      "75/75 - 0s - loss: 8.2544e-06 - accuracy: 0.3535\n",
      "Epoch 49/150\n",
      "75/75 - 0s - loss: 7.3935e-06 - accuracy: 0.3565\n",
      "Epoch 50/150\n",
      "75/75 - 0s - loss: 6.6701e-06 - accuracy: 0.3571\n",
      "Epoch 51/150\n",
      "75/75 - 0s - loss: 5.9925e-06 - accuracy: 0.3609\n",
      "Epoch 52/150\n",
      "75/75 - 0s - loss: 5.3955e-06 - accuracy: 0.3623\n",
      "Epoch 53/150\n",
      "75/75 - 1s - loss: 4.8712e-06 - accuracy: 0.3657\n",
      "Epoch 54/150\n",
      "75/75 - 0s - loss: 4.3555e-06 - accuracy: 0.3680\n",
      "Epoch 55/150\n",
      "75/75 - 1s - loss: 3.9535e-06 - accuracy: 0.3692\n",
      "Epoch 56/150\n",
      "75/75 - 0s - loss: 3.5527e-06 - accuracy: 0.3713\n",
      "Epoch 57/150\n",
      "75/75 - 0s - loss: 3.2177e-06 - accuracy: 0.3751\n",
      "Epoch 58/150\n",
      "75/75 - 0s - loss: 2.8994e-06 - accuracy: 0.3782\n",
      "Epoch 59/150\n",
      "75/75 - 0s - loss: 2.6387e-06 - accuracy: 0.3806\n",
      "Epoch 60/150\n",
      "75/75 - 0s - loss: 2.3708e-06 - accuracy: 0.3831\n",
      "Epoch 61/150\n",
      "75/75 - 0s - loss: 2.1529e-06 - accuracy: 0.3845\n",
      "Epoch 62/150\n",
      "75/75 - 0s - loss: 1.9321e-06 - accuracy: 0.3870\n",
      "Epoch 63/150\n",
      "75/75 - 0s - loss: 1.7576e-06 - accuracy: 0.3902\n",
      "Epoch 64/150\n",
      "75/75 - 0s - loss: 1.5942e-06 - accuracy: 0.3902\n",
      "Epoch 65/150\n",
      "75/75 - 1s - loss: 1.4394e-06 - accuracy: 0.3929\n",
      "Epoch 66/150\n",
      "75/75 - 0s - loss: 1.3078e-06 - accuracy: 0.3940\n",
      "Epoch 67/150\n",
      "75/75 - 1s - loss: 1.1874e-06 - accuracy: 0.3965\n",
      "Epoch 68/150\n",
      "75/75 - 0s - loss: 1.0730e-06 - accuracy: 0.3984\n",
      "Epoch 69/150\n",
      "75/75 - 0s - loss: 9.7850e-07 - accuracy: 0.3996\n",
      "Epoch 70/150\n",
      "75/75 - 1s - loss: 8.8887e-07 - accuracy: 0.4015\n",
      "Epoch 71/150\n",
      "75/75 - 0s - loss: 8.0703e-07 - accuracy: 0.4026\n",
      "Epoch 72/150\n",
      "75/75 - 1s - loss: 7.3219e-07 - accuracy: 0.4042\n",
      "Epoch 73/150\n",
      "75/75 - 1s - loss: 6.6759e-07 - accuracy: 0.4055\n",
      "Epoch 74/150\n",
      "75/75 - 0s - loss: 6.0738e-07 - accuracy: 0.4067\n",
      "Epoch 75/150\n",
      "75/75 - 1s - loss: 5.5033e-07 - accuracy: 0.4086\n",
      "Epoch 76/150\n",
      "75/75 - 1s - loss: 5.0321e-07 - accuracy: 0.4093\n",
      "Epoch 77/150\n",
      "75/75 - 0s - loss: 4.5935e-07 - accuracy: 0.4111\n",
      "Epoch 78/150\n",
      "75/75 - 0s - loss: 4.1733e-07 - accuracy: 0.4124\n",
      "Epoch 79/150\n",
      "75/75 - 0s - loss: 3.7921e-07 - accuracy: 0.4135\n",
      "Epoch 80/150\n",
      "75/75 - 0s - loss: 3.4584e-07 - accuracy: 0.4137\n",
      "Epoch 81/150\n",
      "75/75 - 1s - loss: 3.1491e-07 - accuracy: 0.4162\n",
      "Epoch 82/150\n",
      "75/75 - 1s - loss: 2.8958e-07 - accuracy: 0.4158\n",
      "Epoch 83/150\n",
      "75/75 - 0s - loss: 2.6240e-07 - accuracy: 0.4181\n",
      "Epoch 84/150\n",
      "75/75 - 0s - loss: 2.3922e-07 - accuracy: 0.4197\n",
      "Epoch 85/150\n",
      "75/75 - 0s - loss: 2.1813e-07 - accuracy: 0.4212\n",
      "Epoch 86/150\n",
      "75/75 - 0s - loss: 1.9970e-07 - accuracy: 0.4223\n",
      "Epoch 87/150\n",
      "75/75 - 1s - loss: 1.8306e-07 - accuracy: 0.4244\n",
      "Epoch 88/150\n",
      "75/75 - 1s - loss: 1.6647e-07 - accuracy: 0.4256\n",
      "Epoch 89/150\n",
      "75/75 - 0s - loss: 1.5223e-07 - accuracy: 0.4269\n",
      "Epoch 90/150\n",
      "75/75 - 1s - loss: 1.3934e-07 - accuracy: 0.4290\n",
      "Epoch 91/150\n",
      "75/75 - 0s - loss: 1.2740e-07 - accuracy: 0.4298\n",
      "Epoch 92/150\n",
      "75/75 - 1s - loss: 1.1696e-07 - accuracy: 0.4311\n",
      "Epoch 93/150\n",
      "75/75 - 1s - loss: 1.0617e-07 - accuracy: 0.4321\n",
      "Epoch 94/150\n",
      "75/75 - 1s - loss: 9.7176e-08 - accuracy: 0.4348\n",
      "Epoch 95/150\n",
      "75/75 - 0s - loss: 8.9482e-08 - accuracy: 0.4348\n",
      "Epoch 96/150\n",
      "75/75 - 1s - loss: 8.1788e-08 - accuracy: 0.4363\n",
      "Epoch 97/150\n",
      "75/75 - 0s - loss: 7.5143e-08 - accuracy: 0.4380\n",
      "Epoch 98/150\n",
      "75/75 - 0s - loss: 6.8448e-08 - accuracy: 0.4399\n",
      "Epoch 99/150\n",
      "75/75 - 0s - loss: 6.2502e-08 - accuracy: 0.4413\n",
      "Epoch 100/150\n",
      "75/75 - 0s - loss: 5.8006e-08 - accuracy: 0.4424\n",
      "Epoch 101/150\n",
      "75/75 - 0s - loss: 5.2760e-08 - accuracy: 0.4453\n",
      "Epoch 102/150\n",
      "75/75 - 0s - loss: 4.8163e-08 - accuracy: 0.4476\n",
      "Epoch 103/150\n",
      "75/75 - 0s - loss: 4.3767e-08 - accuracy: 0.4491\n",
      "Epoch 104/150\n",
      "75/75 - 0s - loss: 4.0119e-08 - accuracy: 0.4499\n",
      "Epoch 105/150\n",
      "75/75 - 0s - loss: 3.6822e-08 - accuracy: 0.4514\n",
      "Epoch 106/150\n",
      "75/75 - 0s - loss: 3.3924e-08 - accuracy: 0.4535\n",
      "Epoch 107/150\n",
      "75/75 - 0s - loss: 3.1476e-08 - accuracy: 0.4539\n",
      "Epoch 108/150\n",
      "75/75 - 0s - loss: 2.8878e-08 - accuracy: 0.4549\n",
      "Epoch 109/150\n",
      "75/75 - 1s - loss: 2.6230e-08 - accuracy: 0.4560\n",
      "Epoch 110/150\n",
      "75/75 - 1s - loss: 2.4082e-08 - accuracy: 0.4579\n",
      "Epoch 111/150\n",
      "75/75 - 1s - loss: 2.1833e-08 - accuracy: 0.4600\n",
      "Epoch 112/150\n",
      "75/75 - 1s - loss: 2.0384e-08 - accuracy: 0.4621\n",
      "Epoch 113/150\n",
      "75/75 - 1s - loss: 1.8786e-08 - accuracy: 0.4633\n",
      "Epoch 114/150\n",
      "75/75 - 0s - loss: 1.6737e-08 - accuracy: 0.4656\n",
      "Epoch 115/150\n",
      "75/75 - 0s - loss: 1.5538e-08 - accuracy: 0.4688\n",
      "Epoch 116/150\n",
      "75/75 - 1s - loss: 1.4239e-08 - accuracy: 0.4702\n",
      "Epoch 117/150\n",
      "75/75 - 0s - loss: 1.2940e-08 - accuracy: 0.4721\n",
      "Epoch 118/150\n",
      "75/75 - 0s - loss: 1.1941e-08 - accuracy: 0.4728\n",
      "Epoch 119/150\n",
      "75/75 - 1s - loss: 1.0642e-08 - accuracy: 0.4763\n",
      "Epoch 120/150\n",
      "75/75 - 1s - loss: 9.9424e-09 - accuracy: 0.4772\n",
      "Epoch 121/150\n",
      "75/75 - 0s - loss: 8.8932e-09 - accuracy: 0.4799\n",
      "Epoch 122/150\n",
      "75/75 - 0s - loss: 8.2937e-09 - accuracy: 0.4805\n",
      "Epoch 123/150\n",
      "75/75 - 0s - loss: 7.3444e-09 - accuracy: 0.4837\n",
      "Epoch 124/150\n",
      "75/75 - 0s - loss: 7.1945e-09 - accuracy: 0.4837\n",
      "Epoch 125/150\n",
      "75/75 - 1s - loss: 5.9954e-09 - accuracy: 0.4868\n",
      "Epoch 126/150\n",
      "75/75 - 0s - loss: 5.4459e-09 - accuracy: 0.4881\n",
      "Epoch 127/150\n",
      "75/75 - 0s - loss: 4.7963e-09 - accuracy: 0.4893\n",
      "Epoch 128/150\n",
      "75/75 - 0s - loss: 4.2967e-09 - accuracy: 0.4910\n",
      "Epoch 129/150\n",
      "75/75 - 0s - loss: 3.7471e-09 - accuracy: 0.4922\n",
      "Epoch 130/150\n",
      "75/75 - 0s - loss: 3.4973e-09 - accuracy: 0.4933\n",
      "Epoch 131/150\n",
      "75/75 - 0s - loss: 3.0976e-09 - accuracy: 0.4948\n",
      "Epoch 132/150\n",
      "75/75 - 0s - loss: 2.8478e-09 - accuracy: 0.4952\n",
      "Epoch 133/150\n",
      "75/75 - 0s - loss: 2.3982e-09 - accuracy: 0.4969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "75/75 - 1s - loss: 2.1484e-09 - accuracy: 0.4977\n",
      "Epoch 135/150\n",
      "75/75 - 0s - loss: 1.9985e-09 - accuracy: 0.4985\n",
      "Epoch 136/150\n",
      "75/75 - 0s - loss: 1.9485e-09 - accuracy: 0.4990\n",
      "Epoch 137/150\n",
      "75/75 - 0s - loss: 1.7487e-09 - accuracy: 0.4998\n",
      "Epoch 138/150\n",
      "75/75 - 0s - loss: 1.5488e-09 - accuracy: 0.5008\n",
      "Epoch 139/150\n",
      "75/75 - 0s - loss: 1.2490e-09 - accuracy: 0.5021\n",
      "Epoch 140/150\n",
      "75/75 - 0s - loss: 1.0992e-09 - accuracy: 0.5025\n",
      "Epoch 141/150\n",
      "75/75 - 0s - loss: 1.0992e-09 - accuracy: 0.5027\n",
      "Epoch 142/150\n",
      "75/75 - 1s - loss: 9.4928e-10 - accuracy: 0.5034\n",
      "Epoch 143/150\n",
      "75/75 - 0s - loss: 7.4943e-10 - accuracy: 0.5042\n",
      "Epoch 144/150\n",
      "75/75 - 0s - loss: 6.4951e-10 - accuracy: 0.5046\n",
      "Epoch 145/150\n",
      "75/75 - 0s - loss: 5.9954e-10 - accuracy: 0.5048\n",
      "Epoch 146/150\n",
      "75/75 - 0s - loss: 5.4958e-10 - accuracy: 0.5054\n",
      "Epoch 147/150\n",
      "75/75 - 1s - loss: 3.9970e-10 - accuracy: 0.5063\n",
      "Epoch 148/150\n",
      "75/75 - 0s - loss: 2.4981e-10 - accuracy: 0.5071\n",
      "Epoch 149/150\n",
      "75/75 - 1s - loss: 1.9985e-10 - accuracy: 0.5073\n",
      "Epoch 150/150\n",
      "75/75 - 1s - loss: 1.4989e-10 - accuracy: 0.5075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f944f712908>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adamax',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"Accuracy\"] )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=150,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    "  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 - 0s - loss: 1.7538 - precision: 0.8324 - recall: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7537639141082764, 0.832402229309082, 0.832402229309082]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 - 0s - loss: 1.7538 - precision: 0.8324 - recall: 0.8324\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-00244e305a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model_loss, model_recall = deep_model.evaluate(\n\u001b[0;32m----> 2\u001b[0;31m     X_test_scaled, y_test_categorical, verbose=2)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Deep Neural Network - Loss: {model_loss},  Recall: {model_recall} \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "model_loss, model_recall = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss},  Recall: {model_recall} \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = deep_model.predict(X_test) \n",
    "predictions = (predictions>0.15) # It will evaluate the logical expression y_predict>0.25 and return True or False\n",
    "predictions_categorical = predictions.astype(int)\n",
    "predictions = np.argmax(predictions_categorical, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " No Diabetes       0.51      0.99      0.68       716\n",
      "Has Diabetes       0.91      0.05      0.10       716\n",
      "\n",
      "    accuracy                           0.52      1432\n",
      "   macro avg       0.71      0.52      0.39      1432\n",
      "weighted avg       0.71      0.52      0.39      1432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true = labels\n",
    "y_pred = predictions\n",
    "target_names = [\"No Diabetes\", \"Has Diabetes\"]\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
